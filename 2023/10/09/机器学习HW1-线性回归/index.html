<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="机器学习HW1-线性回归, J&amp;Ocean BLOG">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>机器学习HW1-线性回归 | J&amp;Ocean BLOG</title>
    <link rel="icon" type="image/x-icon, image/vnd.microsoft.icon" href="/favicon.ico">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 6.3.0"></head>



   <style>
    body{
       background-image: url(https://github.com/JIANG-Wu-19/JIANG-Wu-19/blob/master/99759389_p0.png?raw=true);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.ico" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">J&amp;Ocean BLOG</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.ico" class="logo-img circle responsive-img">
        
        <div class="logo-name">J&amp;Ocean BLOG</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/7.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">机器学习HW1-线性回归</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">
                                <span class="chip bg-color">线性回归</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                机器学习
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-10-09
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    6.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    30 分
                </div>
                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p>这是一个有部分代码缺失的notebook，需要完成的就是将 ### START CODE HERE ### ### END CODE HERE ###之间的代码补全</p>
<p>某城市的电网系统需要升级，以应对日益增长的用电需求。电网系统需要考虑最高温度对城市的峰值用电量的影响。项目负责人需要预测明天城市的峰值用电量，他搜集了以往的数据。现在，负责人提供了他搜集到的数据，并请求你帮他训练出一个模型，这个模型能够很好地预测明天城市的峰值用电量。</p>
<h2 id="1-准备"><a href="#1-准备" class="headerlink" title="1- 准备"></a>1- 准备</h2><p>先导入必要的python包</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> time
<span class="token operator">%</span>matplotlib inline<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>导入负责人提供的数据，并可视化数据</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">data <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'data.txt'</span><span class="token punctuation">)</span>
<span class="token comment">#data 第一列为温度信息 第二列为人口信息</span>
X_raw <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment">#data 第三列为用电量信息</span>
Y <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'High temperature'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Peak demand '</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_raw<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'X shape:'</span><span class="token punctuation">,</span>X_raw<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Y shape:'</span><span class="token punctuation">,</span>Y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'some X[:5]:\n'</span><span class="token punctuation">,</span>X_raw<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'some Y[:5]:\n'</span><span class="token punctuation">,</span>Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>X shape: (80, 1)
Y shape: (80, 1)
some X[:5]:
 [[38.24]
 [36.53]
 [32.92]
 [26.59]
 [20.05]]
some Y[:5]:
 [[4.04]
 [2.84]
 [3.2 ]
 [3.42]
 [2.32]]
</code></pre>
<p><img src="/imgs/mlhw1/output_6_1.png" alt="png"></p>
<p>根据对数据可视化结果的分析，决定使用回归算法训练一个模型，用来预测明天城市的峰值用电量。首先考虑单变量的线性回归模型。</p>
<h2 id="2-单变量线性回归理论介绍"><a href="#2-单变量线性回归理论介绍" class="headerlink" title="2- 单变量线性回归理论介绍"></a>2- 单变量线性回归理论介绍</h2><h3 id="单变量线性回归模型"><a href="#单变量线性回归模型" class="headerlink" title="单变量线性回归模型"></a>单变量线性回归模型</h3><p>单变量线性回归的模型由两个参数$\theta_0$,$\theta_1$来表示一条直线：$$Peak\ demand \approx \theta_0 + \theta_1 \cdot (High\ temperature) 。$$</p>
<p>我们的目标也就是找到一条”最符合”的直线，确定这条直线的参数$\theta_i$。</p>
<p><img src="/imgs/mlhw1/lines.jpg" alt="functions"><br>设输入的特征——最高温度(F)为$x^{(i)} \in \mathbb{R}^{n+1}$，$i&#x3D;1,\cdots,m$。$m$为样本总数，在该例子中$m$&#x3D;80。$n$为特征的个数，这里为$1$。则：$x^{(i)} \in \mathbb{R}^2 &#x3D; \begin{bmatrix} 1 \ \text{high temperature for day} i\end{bmatrix}。$</p>
<p>设输出为$y^{(i)} \in \mathbb{R}$，表示第$i$天的峰值用电量。</p>
<p>参数为$\theta \in \mathbb{R}^{n+1} &#x3D; \begin{bmatrix} \theta_0 \ \theta_1 \ \vdots \ \theta_n \end{bmatrix}$。这里$n&#x3D;1$。</p>
<p>在该例子中，模型为一条直线，模型可表示为：<br>$$h_{\theta}(x) &#x3D; \theta^T x &#x3D; \theta_0 + \theta_1 x 。$$</p>
<h3 id="注意："><a href="#注意：" class="headerlink" title="注意："></a><strong>注意</strong>：</h3><p>这里的$\theta^T$是一个向量，$\theta_0,\theta_1$是标量。使用向量化表示的原因为：（1）简化数学公式的书写（2）与程序代码中的表示保持一致，且使用向量化的代码实现可以加速运算，<strong>因此一般能不用<code>for</code>循环的地方都不用<code>for</code>循环</strong>。 </p>
<p>下面用一个简单的例子说明向量化的代码运算更快。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># # 随机初始化两个向量，计算它们的点积</span>
<span class="token comment"># x = np.random.rand(10000000,1)</span>
<span class="token comment"># y = np.random.rand(10000000,1)</span>
<span class="token comment"># ans = 0</span>
<span class="token comment"># start = time.time()</span>
<span class="token comment"># for i in range(10000000):</span>
<span class="token comment">#     ans += x[i,0]/timesy[i,0]</span>
<span class="token comment"># end = time.time()</span>
<span class="token comment"># print('for循环的计算时间: %.2fs'%(end - start))</span>
<span class="token comment"># print('计算结果：%.2f'%(ans))</span>
<span class="token comment"># start = time.time()</span>
<span class="token comment"># ans = np.dot(x.T,y)</span>
<span class="token comment"># end = time.time()</span>
<span class="token comment"># print('向量化的计算时间: %.2fs'%(end - start))</span>
<span class="token comment"># print('计算结果：%.2f'%(ans))</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>因为$\theta_0 + \theta_1 x&#x3D;\begin{bmatrix} 1 \quad x \end{bmatrix} \begin{bmatrix} \theta_0 \ \theta_1 \end{bmatrix} 。$<br>因此，为了方便编程，我们需要给每一个$x^{(i)}$的前面再加一列1。使得每一个$x^{(i)}$成为一个2维向量。</p>
<h3 id="预测结果"><a href="#预测结果" class="headerlink" title="预测结果"></a>预测结果</h3><p>模型需要根据输入自变量 $x^{(i)}$ 和参数 $\theta$ 来输出预测结果 $predict_y^{(i)}$。</p>
<p>将自变量 $x^{(i)}$ 作为模型的输入，模型根据输入和当前参数 $\theta$ 输出预测结果：</p>
<p>$$<br>predict_y^{(i)} &#x3D; h_\theta(x^{(i)})。<br>$$</p>
<p>其中 $h_\theta()$ 为模型在参数为 $\theta$ 情况下，对于输入的预测函数。  </p>
<p>在预测阶段，$x$作为自变量。</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>模型的预测结果和实际结果有差距，为了衡量它们之间的差距，或者说量化使用这个模型产生的损失，我们定义损失函数$l(predict_y^{(i)}, y^{(i)})$。这里我们使用平方损失：<br>$$<br>l(predict_y, y) &#x3D; \left ( predict_y^{(i)} - y^{(i)} \right )^2。<br>$$</p>
<p>上述损失函数表示一个样本的损失，整个训练集的损失使用$J(\theta)$表示：<br>$$<br>\begin{aligned}<br>J(\theta) &amp; &#x3D; \frac{1}{2m} \sum_{i&#x3D;1}^{m}l(predict_y^{(i)}, y^{(i)}) \<br>&amp; &#x3D; \frac{1}{2m} \sum_{i&#x3D;1}^{m} \left ( h_\theta(x^{(i)}) - y^{(i)} \right )^2 \<br>&amp; &#x3D; \frac{1}{2m} \sum_{i&#x3D;1}^{m} \left ( \theta^T x^{(i)} - y^{(i)} \right )^2。<br>\end{aligned}<br>$$<br>（其中数字2的作用是方便求导时的运算）</p>
<p>为了使模型取得较好的预测效果，需要最小化训练集上的损失，即$\underset{\theta}{\min} J(\theta)$。</p>
<p>在损失阶段，$\theta$ 作为自变量。</p>
<h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>为了得到使损失函数$J(\theta)$最小化的$\theta$，可以使用梯度下降法。</p>
<p>损失函数$J(\theta)$的函数图像如下：<br><img src="/imgs/mlhw1/loss_function_j.png" alt="损失函数J"></p>
<p>损失函数$J(\theta)$关于参数向量$\theta$中的一个参数，比如$\theta_1$的函数图为：<br><img src="/imgs/mlhw1/theta-J.png" alt="theta-J 函数图"></p>
<p>假设一开始$J(\theta)$的值在紫色点上，为了降低$J(\theta)$值，需要$\theta_1$往右边移动，这个方向是$J(\theta)$在$\theta_1$上的负梯度。只要$\theta$不断往负梯度方向移动，$J(\theta)$一定可以降到最低值。梯度下降法就是使参数$\theta$不断往负梯度移动，经过有限次迭代(更新$\theta$值)之后，损失函数$J(\theta)$达到最低值。</p>
<p>梯度下降法的过程：</p>
<ol>
<li><p>初始化参数向量$\theta$。</p>
</li>
<li><p>开始迭代</p>
<p>A.根据实际输入$x$和参数$\theta$预测输出，</p>
<p>B. 根据预测输出值和实际输出值之间的差距，计算损失函数$J(\theta)$，</p>
<p>C. 计算损失函数对$\theta$的梯度，</p>
<p>D. 更新参数$\theta$。</p>
</li>
</ol>
<h2 id="3-实现单变量线性回归模型"><a href="#3-实现单变量线性回归模型" class="headerlink" title="3- 实现单变量线性回归模型"></a>3- 实现单变量线性回归模型</h2><p>现在，我们开始实现 Regression 算法。</p>
<h3 id="任务1："><a href="#任务1：" class="headerlink" title="任务1："></a><strong>任务1：</strong></h3><p>首先在$X$前面加上一列1，表示参数$\theta_0$的系数，方便运算。$X$是形状为$(m,1)$的矩阵，一共$m$行数据，我们需要为每一行数据的前面加一列1，如下所示：<br>$$<br>\begin{bmatrix} x^{(0)} \ x^{(1)} \ \vdots \x^{(m-1)}  \end{bmatrix} \longrightarrow<br>\begin{bmatrix} 1\quad x^{(0)} \ 1\quad x^{(1)} \ \vdots \ 1\ x^{(m-1)}  \end{bmatrix}。<br>$$<br><strong>提示</strong>：可以使用<code>np.hstack</code>把两个矩阵水平合在一起。用1初始化向量或矩阵的函数是<code>np.ones</code>。(函数详情可使用python的帮助函数<code>help</code>，比如<code>help(np.ones)</code>，或者自行用搜索引擎检索。)</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">preprocess_data</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""输入预处理 在X前面加一列1
    参数：
        X:原始数据,shape为(m,1)
        
    返回：
        X_train: 在X加一列1的数据,shape为(m,2)
    """</span>

    m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>   <span class="token comment"># m 是数据X的行数</span>
    <span class="token comment">### START CODE HERE ###</span>
    
    one_column<span class="token operator">=</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    X_train<span class="token operator">=</span>np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>one_column<span class="token punctuation">,</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment">### END CODE HERE ###</span>
    <span class="token keyword">return</span> X_train<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> preprocess_data<span class="token punctuation">(</span>X_raw<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'new X shape:'</span><span class="token punctuation">,</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Y shape:'</span><span class="token punctuation">,</span>Y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'new X[:5,:]=\n'</span><span class="token punctuation">,</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Y[:5,:]=\n'</span><span class="token punctuation">,</span>Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>new X shape: (80, 2)
Y shape: (80, 1)
new X[:5,:]=
 [[ 1.   38.24]
 [ 1.   36.53]
 [ 1.   32.92]
 [ 1.   26.59]
 [ 1.   20.05]]
Y[:5,:]=
 [[4.04]
 [2.84]
 [3.2 ]
 [3.42]
 [2.32]]
</code></pre>
<h3 id="任务2："><a href="#任务2：" class="headerlink" title="任务2："></a><strong>任务2：</strong></h3><p>接着，初始化参数向量$\theta$。$\theta$的shape是$(2,1)$，我们随机初始化$\theta$。</p>
<p><strong>提示</strong>：numpy的随机函数是<code>np.random.rand</code>。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">init_parameter</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""初始化参数
    参数：
        shape: 参数形状
        
    返回：
        theta_init: 初始化后的参数
    """</span>
    
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    m<span class="token punctuation">,</span> n <span class="token operator">=</span> shape
    <span class="token comment">### START CODE HERE ###</span>

    theta_init <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>m<span class="token punctuation">,</span>n<span class="token punctuation">)</span>

    <span class="token comment">### END CODE HERE ###</span>
    
    <span class="token keyword">return</span> theta_init<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">theta <span class="token operator">=</span> init_parameter<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'theta shape is '</span><span class="token punctuation">,</span>theta<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'theta = '</span><span class="token punctuation">,</span>theta<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre><code>theta shape is  (2, 1)
theta =  [[0.5488135 ]
 [0.71518937]]
</code></pre>
<h3 id="任务3："><a href="#任务3：" class="headerlink" title="任务3："></a><strong>任务3：</strong></h3><p>通过已知 $X$ 和参数 $\theta$ 计算预测的 $predict_Y$ 值。</p>
<p>由于使用<code>for</code>循环单独计算每个预测值效率不高，因此我们需要用向量化的方法代替<code>for</code>循环。$X$ 大小为$m \times (n+1)$($n$表示特征数量，这里$n&#x3D;1$)，每行是一条样本特征向量，$\theta$ 大小为$(n+1) \times 1$，可以使用$X \theta$（矩阵相乘）计算所有样本的预测结果,大小为$m\times 1$。于是这里的线性模型就可以表示为：<br>$$<br>h_{\theta}(X) &#x3D; X \theta。<br>$$<br>这里$h_{\theta}(X)$的大小为$m \times 1$，结果上等于 $predict_Y_\theta$。</p>
<p><strong>提示</strong>：矩阵相乘 <code>np.dot(矩阵1，矩阵2)</code>。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">compute_predict_Y</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span>theta<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""计算预测结果
    参数：
        X: 训练集数据特征,shape: (m, 2)
        theta: 参数,shape: (2, 1)

    返回：
        predict_Y: 预测结果,shape: (m,1)
    """</span>
    
    <span class="token comment">### START CODE HERE ###</span>
    predict_Y <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span>theta<span class="token punctuation">)</span>
    <span class="token comment">### END CODE HERE ###</span>
    <span class="token keyword">return</span> predict_Y
predict_Y <span class="token operator">=</span> compute_predict_Y<span class="token punctuation">(</span>X<span class="token punctuation">,</span>theta<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>predict_Y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>[[27.89765487]
 [26.67468106]
 [24.09284744]
 [19.56569876]
 [14.8883603 ]]
</code></pre>
<h3 id="任务4："><a href="#任务4：" class="headerlink" title="任务4："></a><strong>任务4：</strong></h3><p>实现计算损失函数$J(\theta)$的函数。<br>从公式<br>$$<br>\begin{aligned}<br>J(\theta) &#x3D; \frac{1}{2m} \sum_{i&#x3D;1}^{m} \left ( predict_y_\theta^{(i)} - y_\theta^{(i)} \right )^2<br>\end{aligned}<br>$$<br>可以看到有个求和，由于使用<code>for</code>循环效率不高，因此需要用向量化的方法代替<code>for</code>循环。$(predict_Y - Y)^2$计算所有样本的损失值，最后求和并除以$2m$得到$J(\theta)$的值，得到的$J(\theta)$是一个标量。<br><strong>提示</strong>：矩阵乘法运算可使用<code>np.dot</code>函数，平方运算可使用<code>np.power(data, 2)</code>函数，求和运算可使用<code>np.sum</code>。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">compute_J</span><span class="token punctuation">(</span>predict_Y<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""计算损失的函数J
    参数：
        predict_Y: 预测结果,shape: (m, 1)
        Y: 训练集数据标签,shape: (m, 1)
        
    返回：
        loss: 损失值
    """</span>
    
    m <span class="token operator">=</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    
    <span class="token comment">### START CODE HERE ###</span>

    loss <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>predict_Y<span class="token operator">-</span>Y<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>m<span class="token punctuation">)</span>
    
    <span class="token comment">### END CODE HERE ###</span>
    
    <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">first_loss <span class="token operator">=</span> compute_J<span class="token punctuation">(</span>predict_Y<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"first_loss = "</span><span class="token punctuation">,</span> first_loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre><code>first_loss =  144.05159786255672
</code></pre>
<h3 id="任务5："><a href="#任务5：" class="headerlink" title="任务5："></a><strong>任务5：</strong></h3><p>计算参数$\theta$的梯度。梯度计算的公式为：<br>$$<br>\frac{\partial J(\theta)}{\partial \theta_j} &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^{m} \left ( \theta^T x^{(i)} - y \right ) x_j^{(i)}。<br>$$<br>向量化公式为：<br>$$<br>\text{gradients} &#x3D;\frac{1}{m} X^T (X \theta - Y) 。<br>$$<br><strong>提示</strong>：矩阵A的转置表示为<code>A.T</code>。$X\theta$就是计算出的predict_Y。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">compute_gradient</span><span class="token punctuation">(</span>predict_Y<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""计算对参数theta的梯度值
    参数：
        predict_Y: 当前预测结果,shape: (m,1)
        Y: 训练集数据标签,shape: (m, 1)
        X: 训练集数据特征,shape: (m, 2)
        
    返回：
        gradients: 对theta的梯度,shape:(2,1)
    """</span>
    
    m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    
    <span class="token comment">### START CODE HERE ###</span>

    gradients <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>m<span class="token punctuation">)</span><span class="token operator">*</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span><span class="token punctuation">(</span>predict_Y<span class="token operator">-</span>Y<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">### END CODE HERE ###</span>
    
    <span class="token keyword">return</span> gradients<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">gradients_first <span class="token operator">=</span> compute_gradient<span class="token punctuation">(</span>predict_Y<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> X<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"gradients_first shape : "</span><span class="token punctuation">,</span> gradients_first<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"gradients_first = "</span><span class="token punctuation">,</span> gradients_first<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre><code>gradients_first shape :  (2, 1)
gradients_first =  [[ 16.0079445 ]
 [459.96770081]]
</code></pre>
<h3 id="任务6："><a href="#任务6：" class="headerlink" title="任务6："></a><strong>任务6：</strong></h3><p>用梯度下降法更新参数$\theta$,实现<code>update_parameters</code>函数。</p>
<p><strong>提示</strong>：parameters &#x3D; $\theta$ - $learning_rate·gradients$</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">update_parameters</span><span class="token punctuation">(</span>theta<span class="token punctuation">,</span> gradients<span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""更新参数theta
    参数：
        theta: 参数,shape: (2, 1)
        gradients: 梯度,shape: (2, 1)
        learning_rate: 学习率,默认为0.0001
        
    返回：
        parameters: 更新后的参数,shape: (2, 1)
    """</span>
    <span class="token comment">### START CODE HERE ###</span>

    parameters <span class="token operator">=</span> theta<span class="token operator">-</span>learning_rate<span class="token operator">*</span>gradients

    <span class="token comment">### END CODE HERE ###</span>
    
    <span class="token keyword">return</span> parameters<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">theta_one_iter <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>theta<span class="token punctuation">,</span> gradients_first<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"theta_one_iter = "</span><span class="token punctuation">,</span> theta_one_iter<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre><code>theta_one_iter =  [[0.54721271]
 [0.6691926 ]]
</code></pre>
<h3 id="任务7："><a href="#任务7：" class="headerlink" title="任务7："></a><strong>任务7：</strong></h3><p>将前面定义的函数整合起来，实现完整的模型训练函数。</p>
<p>$\theta$迭代更新 <code>iter_num</code>次。迭代次数<code>iter_num</code>也是一个超参数，如果<code>iter_num</code>太小，损失函数$J(\theta)$还没有收敛；如果<code>iter_num</code>太大，损失函数$J(\theta)$早就收敛了，过多的迭代浪费时间。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">model</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> theta<span class="token punctuation">,</span> iter_num <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""线性回归模型
    参数：
        X: 训练集数据特征,shape: (m, n+1)
        Y: 训练集数据标签,shape: (m, 1)
        iter_num: 梯度下降的迭代次数
        theta: 初始化的参数,shape: (n+1, 1)
        learning_rate: 学习率,默认为0.0001
        
    返回：
        loss_history: 每次迭代的损失值
        theta_history: 每次迭代更新后的参数
        theta: 训练得到的参数
    """</span>
    
    loss_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    theta_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>iter_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
        <span class="token comment">### START CODE HERE ###</span>
        <span class="token comment"># 预测</span>
        predict_Y <span class="token operator">=</span> compute_predict_Y<span class="token punctuation">(</span>X<span class="token punctuation">,</span>theta<span class="token punctuation">)</span>
        <span class="token comment"># 计算损失</span>
        loss <span class="token operator">=</span> compute_J<span class="token punctuation">(</span>predict_Y<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
        <span class="token comment"># 计算梯度</span>
        gradients <span class="token operator">=</span> compute_gradient<span class="token punctuation">(</span>predict_Y<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>X<span class="token punctuation">)</span>
        <span class="token comment"># 更新参数</span>
        theta <span class="token operator">=</span> update_parameters<span class="token punctuation">(</span>theta<span class="token punctuation">,</span>gradients<span class="token punctuation">,</span>learning_rate<span class="token punctuation">)</span>
        <span class="token comment">### END CODE HERE ###</span>
        
        loss_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
        theta_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>theta<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> loss_history<span class="token punctuation">,</span> theta_history<span class="token punctuation">,</span> theta<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 感兴趣的同学可以自行尝试不同的学习率和迭代次数，最后提交时以100次迭代和0.0001的学习率重新运行一遍再提交</span>

loss_history<span class="token punctuation">,</span> theta_history<span class="token punctuation">,</span> theta <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> theta<span class="token punctuation">,</span> iter_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"theta = "</span><span class="token punctuation">,</span> theta<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>loss_history<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loss = "</span><span class="token punctuation">,</span> loss_history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>theta =  [[0.52732144]
 [0.09027749]]
loss =  0.09087253295782578
</code></pre>
<p><img src="/imgs/mlhw1/output_33_1.png" alt="png"></p>
<p>下面是学习到的线性模型与原始数据的关系可视化。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">42</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>x<span class="token operator">/</span>timestheta<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span>theta<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>


<pre><code>---------------------------------------------------------------------------

NameError                                 Traceback (most recent call last)

Cell In[17], line 3
      1 plt.scatter(X[:,1],Y)
      2 x = np.arange(10,42)
----&gt; 3 plt.plot(x,x/timestheta[1][0]+theta[0][0],&#39;r&#39;)


NameError: name &#39;timestheta&#39; is not defined
</code></pre>
<p><img src="/imgs/mlhw1/output_35_1.png" alt="png"></p>
<p>现在直观地了解一下梯度下降的过程。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">theta_0 <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>
theta_1 <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>
theta_0<span class="token punctuation">,</span> theta_1 <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>theta_0<span class="token punctuation">,</span>theta_1<span class="token punctuation">)</span>
J <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>theta_0<span class="token punctuation">)</span>
predict_Ys <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>predict_Y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>theta_0<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>theta_1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>predict_Ys<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>J<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        predict_Y <span class="token operator">=</span> compute_predict_Y<span class="token punctuation">(</span>X<span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>theta_0<span class="token punctuation">[</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span>theta_1<span class="token punctuation">[</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        J<span class="token punctuation">[</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> compute_J<span class="token punctuation">(</span>predict_Y<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>theta_0<span class="token punctuation">,</span> theta_1<span class="token punctuation">,</span> J<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> alpha <span class="token operator">=</span> <span class="token number">0.6</span><span class="token punctuation">,</span> cmap <span class="token operator">=</span> plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>coolwarm<span class="token punctuation">)</span>
C <span class="token operator">=</span> plt<span class="token punctuation">.</span>contour<span class="token punctuation">(</span>theta_0<span class="token punctuation">,</span> theta_1<span class="token punctuation">,</span> J<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> colors <span class="token operator">=</span> <span class="token string">'black'</span><span class="token punctuation">)</span>

<span class="token comment"># 画出损失函数J的历史位置</span>
history_num <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>theta_history<span class="token punctuation">)</span>
theta_0_history <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>history_num<span class="token punctuation">)</span>
theta_1_history <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>history_num<span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>history_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    theta_0_history<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>theta_1_history<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> theta_history<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>theta_history<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>theta_0_history<span class="token punctuation">,</span> theta_1_history<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">"r"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>(50, 50)
(50, 50)
(80, 1)
(50, 50)





&lt;matplotlib.collections.PathCollection at 0x22dd1ba5990&gt;
</code></pre>
<p>​<br><img src="/imgs/mlhw1/output_37_2.png" alt="png"><br>​    </p>
<p>可以看到，$J(\theta)$的值不断地往最低点移动。在y轴，$J(\theta)$下降的比较快，在x轴，$J(\theta)$下降的比较慢。</p>
<h2 id="4-实现多变量线性回归模型"><a href="#4-实现多变量线性回归模型" class="headerlink" title="4- 实现多变量线性回归模型"></a>4- 实现多变量线性回归模型</h2><p>上述例子是单变量回归的例子，样本的特征只有一个一天的最高温度。负责人经过分析后发现，城市一天的峰值用电量还与城市人口有关系，因此，他在回归模型中添加城市人口变量$x_2$，你的任务是训练这个多变量回归方程：<br>$$<br>h(x) &#x3D; \theta^T x &#x3D; \theta_0 * 1 + \theta_1 * x_1 + \theta_2 * x_2。<br>$$<br>之前实现的梯度下降法使用的对象是$\theta$和$X$向量，实现的梯度下降函数适用于单变量回归和多变量回归。不难发现上面使用的向量化公式在多变量回归里依然不变，因此代码也基本一致,直接调用前面实现的函数即可。</p>
<h3 id="任务8："><a href="#任务8：" class="headerlink" title="任务8："></a><strong>任务8：</strong></h3><p>现在，训练一个多变量回归模型。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#读取数据，X取data的前两列</span>
X <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment">### START CODE HERE ###</span>

<span class="token comment"># 直接调用上面实现过的函数</span>
<span class="token comment"># 同样为X的前面添加一列1,使得X的shape从80x2 -> 80x3</span>
X <span class="token operator">=</span> preprocess_data<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
<span class="token comment"># 初始化参数theta ,theta的shape应为 3x1</span>
theta <span class="token operator">=</span> init_parameter<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 传入模型训练,learning_rate设为0.0001</span>
loss_history<span class="token punctuation">,</span> theta_history<span class="token punctuation">,</span> theta <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>theta<span class="token punctuation">,</span>iter_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>learning_rate<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>

<span class="token comment">### END CODE HERE ###</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"theta = "</span><span class="token punctuation">,</span> theta<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>loss_history<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loss = "</span><span class="token punctuation">,</span> loss_history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>theta =  [[0.52593585]
 [0.06715361]
 [0.57583208]]
loss =  0.10300473270580186
</code></pre>
<p><img src="/imgs/mlhw1/output_40_1.png" alt="png"></p>
<h2 id="5-特征归一化"><a href="#5-特征归一化" class="headerlink" title="5- 特征归一化"></a>5- 特征归一化</h2><p>特征归一化可以确保特征在相同的尺度，加快梯度下降的收敛过程。</p>
<h3 id="任务9："><a href="#任务9：" class="headerlink" title="任务9："></a><strong>任务9：</strong></h3><p>对数据进行零均值单位方差归一化处理。零均值单位方差归一化公式：<br>$$<br>x_i &#x3D; \frac{x_i - \mu_i}{\sigma_i}<br>$$<br>其中$i$表示第$i$个特征，$\mu_i$表示第$i$个特征的均值，$\sigma_i$表示第$i$个特征的标准差。进行零均值单位方差归一化处理后，数据符合标准正态分布，即均值为0，标准差为1。</p>
<p><strong>注意</strong>，使用新样本进行预测时，需要对样本的特征进行相同的缩放处理。</p>
<p><strong>提示</strong>：求特征的均值，使用numpy的函数<code>np.mean</code>;求特征的标准差，使用numpy的函数<code>np.std</code>，需要注意对哪个维度求均值和标准差。比如，对矩阵A的每列求均值<code>np.mean(A,axis=0)</code>。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">### START CODE HERE ###</span>

<span class="token comment"># 计算特征的均值 mu</span>
mu <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>X<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># 计算特征的标准差 sigma</span>
sigma <span class="token operator">=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>X<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># 零均值单位方差归一化</span>
X_norm <span class="token operator">=</span> <span class="token punctuation">(</span>X<span class="token operator">-</span>mu<span class="token punctuation">)</span><span class="token operator">/</span>sigma

<span class="token comment"># 训练多变量回归模型</span>
<span class="token comment"># X_norm前面加一列1</span>
X <span class="token operator">=</span> preprocess_data<span class="token punctuation">(</span>X_norm<span class="token punctuation">)</span>
<span class="token comment"># 初始化参数theta</span>
theta <span class="token operator">=</span> init_parameter<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 传入模型训练,learning_rate设为0.1</span>
loss_history<span class="token punctuation">,</span> theta_history<span class="token punctuation">,</span> theta <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>theta<span class="token punctuation">,</span>iter_num<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>learning_rate<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>

<span class="token comment">### END CODE HERE ###</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"mu = "</span><span class="token punctuation">,</span> mu<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sigma = "</span><span class="token punctuation">,</span> sigma<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"theta = "</span><span class="token punctuation">,</span> theta<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>loss_history<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"loss = "</span><span class="token punctuation">,</span> loss_history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>mu =  [25.617  1.131]
sigma =  [8.8648434 0.3606716]
theta =  [[2.86181356]
 [0.70424286]
 [0.04097817]]
loss =  0.08591601385802586
</code></pre>
<p><img src="/imgs/mlhw1/output_42_1.png" alt="png"></p>
<p>我们来直观地了解特征尺度归一化的梯度下降的过程。这里只展示单变量回归梯度下降过程。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">X_show <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>
X_show <span class="token operator">=</span> preprocess_data<span class="token punctuation">(</span>X_show<span class="token punctuation">)</span>

theta_0 <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>
theta_1 <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span>
theta_0<span class="token punctuation">,</span> theta_1 <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>theta_0<span class="token punctuation">,</span>theta_1<span class="token punctuation">)</span>
J <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>theta_0<span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        predict_Y <span class="token operator">=</span> compute_predict_Y<span class="token punctuation">(</span>X_show<span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.877</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span>theta_0<span class="token punctuation">[</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span>theta_1<span class="token punctuation">[</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        J<span class="token punctuation">[</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> compute_J<span class="token punctuation">(</span>predict_Y<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>theta_0<span class="token punctuation">,</span> theta_1<span class="token punctuation">,</span> J<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> alpha <span class="token operator">=</span> <span class="token number">0.6</span><span class="token punctuation">,</span> cmap <span class="token operator">=</span> plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>coolwarm<span class="token punctuation">)</span>
C <span class="token operator">=</span> plt<span class="token punctuation">.</span>contour<span class="token punctuation">(</span>theta_0<span class="token punctuation">,</span> theta_1<span class="token punctuation">,</span> J<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> colors <span class="token operator">=</span> <span class="token string">'black'</span><span class="token punctuation">)</span>

<span class="token comment"># 画出损失函数J的历史位置</span>
history_num <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>theta_history<span class="token punctuation">)</span>
theta_0_history <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>history_num<span class="token punctuation">)</span>
theta_1_history <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>history_num<span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>history_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    theta_0_history<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>theta_1_history<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> theta_history<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>theta_history<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>theta_0_history<span class="token punctuation">,</span> theta_1_history<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">"r"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>




<pre><code>&lt;matplotlib.collections.PathCollection at 0x22dd1be2e10&gt;
</code></pre>
<p>​<br><img src="/imgs/mlhw1/output_44_1.png" alt="png"><br>​    </p>
<p>可以看到，$J(\theta)$的值不断地往最低点移动。与没有进行特征尺度归一化的图相比，归一化后，每个维度的变化幅度大致相同，这有助于$J(\theta)$的值快速下降到最低点。</p>
<h2 id="6-法线方程-The-normal-equations"><a href="#6-法线方程-The-normal-equations" class="headerlink" title="6- 法线方程 (The normal equations)"></a>6- 法线方程 (The normal equations)</h2><p>对于求函数极小值问题，可以使用求导数的方法，令函数的导数为0，然后求解方程，得到解析解。法线方程正是使用这种方法来求解损失函数$J(\theta)$的极小值，而线性回归的损失函数$J(\theta)$是一个凸函数，所以极小值就是最小值。</p>
<p>法线方程的求解过程详见课件，法线方程的公式是：<br>$$<br>\theta &#x3D; (X^T X)^{-1} X^T Y<br>$$</p>
<p>如果$m \le n +1$，那么$X^T X$是奇异矩阵，即$X^T X$不可逆。<br>$X^T X$不可逆的原因可能是：</p>
<ul>
<li>特征之间冗余，比如特征向量中两个特征是线性相关的。</li>
<li>特征太多，删去一些特征再进行运算。</li>
</ul>
<p>法线方程的缺点之一就是会出现$X^T X$不可逆的情况，可以通过正则化的方式解决。另一个缺点是，如果样本的个数太多，特征数量太多($n \gt 10000$)，法线方程的运算会很慢（求逆矩阵的运算复杂）。</p>
<h3 id="任务10："><a href="#任务10：" class="headerlink" title="任务10："></a><strong>任务10：</strong></h3><p>下面来实现法线方程。<br><strong>提示</strong>：Numpy 求逆矩阵的函数是<code>np.linalg.inv</code>。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">normal_equation</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""法线方程求解线性回归方程的参数
    参数：
        X: 训练集数据特征,shape: (m, n+1)
        Y: 训练集数据标签,shape: (m, 1)
        
    返回：
        theta: 线性回归方程的参数
    """</span>
    
    <span class="token comment">### START CODE HERE ###</span>
        
    theta <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">,</span>Y<span class="token punctuation">)</span>

    <span class="token comment">### END CODE HERE ###</span>
    
    <span class="token keyword">return</span> theta<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<pre class="line-numbers language-python" data-language="python"><code class="language-python">theta <span class="token operator">=</span> normal_equation<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"theta = "</span><span class="token punctuation">,</span> theta<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre><code>theta =  [[2.861875  ]
 [0.70429906]
 [0.04092011]]
</code></pre>
<p>可以自行对比一下直接用正规方程求解出的$\theta$与用线性回归模型训练出的$\theta$之间的差异，会”惊奇”地发现两者几乎一模一样。</p>
<h2 id="7-预测结果"><a href="#7-预测结果" class="headerlink" title="7- 预测结果"></a>7- 预测结果</h2><h3 id="任务11："><a href="#任务11：" class="headerlink" title="任务11："></a><strong>任务11：</strong></h3><p>假设明天的最高温度是$x_1 &#x3D; 40$°C，人口$x_2 &#x3D; 3.3$百万，使用通过正规方程计算得到的$\theta$预测明天的城市的峰值用电量（单位：GW）吧！<br><strong>注意</strong>，$x$要进行同样的特征尺度归一化处理。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>theta<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""预测峰值用电量
    参数：
        X: 需要预测数据的特征,shape: (m, n+1), 这里只预测一天的结果, m=1
        theta: 最终确定的参数,shape: (n+1, 1)
        
    返回：
        prediction: 预测结果,shape: (m, 1)
    """</span>

    <span class="token comment">### START CODE HERE ###</span>

    <span class="token comment"># 零均值单位方差归一化</span>
    x <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token operator">-</span>mu<span class="token punctuation">)</span><span class="token operator">/</span>sigma
    <span class="token comment"># 在x前面加一列</span>
    x <span class="token operator">=</span> preprocess_data<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#用theta和处理后的x计算预测值</span>
    prediction <span class="token operator">=</span> compute_predict_Y<span class="token punctuation">(</span>x<span class="token punctuation">,</span>theta<span class="token punctuation">)</span>

    <span class="token comment">### END CODE HERE ###</span>

    <span class="token keyword">return</span> prediction

<span class="token comment">#明天的特征</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">,</span><span class="token number">3.3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预计明天的峰值用电量为：%.2f GW'</span><span class="token operator">%</span><span class="token punctuation">(</span>predict<span class="token punctuation">(</span>theta<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>预计明天的峰值用电量为：4.25 GW
</code></pre>
<h2 id="8-多项式回归"><a href="#8-多项式回归" class="headerlink" title="8- 多项式回归"></a>8- 多项式回归</h2><p>以上都是线性模型，当我们数据的特征$X$与预测结果$Y$之间没有明显的线性关系，而且又找不到合适的映射函数时，可以尝试多项式回归。<br>下面导入另一组最高气温与用电量数据，我们用线性模型试一试看看效果发现并不太好。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">data1 <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'data1.txt'</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> data1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> data1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span>
theta <span class="token operator">=</span> normal_equation<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span>theta<span class="token punctuation">)</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>




<pre><code>[&lt;matplotlib.lines.Line2D at 0x22dd1b75290&gt;]
</code></pre>
<p>​<br><img src="/imgs/mlhw1/output_53_1.png" alt="png"><br>​    </p>
<p>多项式回归的最大优点就是可以通过增加$X$的高次项对实测点进行逼近，直至满意为止。事实上，多项式回归可以处理相当一类非线性问题，它在回归分析中占有重要的地位，<strong>因为任一函数都可以分段用多项式来逼近</strong>。因此，在通常的实际问题中，不论依变量与其他自变量的关系如何，我们总可以用多项式回归来进行分析。假设数据的特征只有一个$a$，多项式的最高次数为$K$，那么多项式回归方程为：<br>$$<br>h(x) &#x3D; \theta^T x &#x3D; \theta_0 \times a^0 + \theta_1 \times a^1 + \theta_2 \times a^2 + \cdots + \theta_K \times a^K。<br>$$<br>若令$x &#x3D; \begin{bmatrix} a^0, a^1, a^2, \cdots, a^K \end{bmatrix}^T$，那么<br>$$<br>h(x) &#x3D; \theta^T x &#x3D; \theta_0 \times x_0 + \theta_1 \times x_1 + \theta_2 \times x_2, \cdots, \theta_K \times x_K，<br>$$<br>这就变为多变量线性回归了。</p>
<h3 id="任务12："><a href="#任务12：" class="headerlink" title="任务12："></a><strong>任务12：</strong></h3><p>现在想要得到一个如下的多项式模型，$K&#x3D;2$，直接用上面的正规方程进行求解。<br>$$<br>    h(x) &#x3D; \theta^T x &#x3D; \theta_0 \times 1 + \theta_1 \times x + \theta_2 \times x^2。<br>$$<br>输入数据$X$变为:<br>$$<br>\begin{bmatrix} x^{(0)} \ x^{(1)} \ \vdots \x^{(m-1)}  \end{bmatrix} \longrightarrow<br>\begin{bmatrix} 1\quad x^{(0)}\quad {x^{(0)}}^2 \ 1\quad x^{(1)} \quad {x^{(1)}}^2\ \vdots \ 1\ x^{(m-1)}\quad {x^{(m-1)}}^2  \end{bmatrix}。<br>$$</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">data1 <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">'data1.txt'</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> data1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> data1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token comment"># m 是数据X的行数</span>
X_square <span class="token operator">=</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>X<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment">### START CODE HERE ###</span>

<span class="token comment"># 对X 前面加1， 后面加平方，变为 m x 3 的矩阵</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>X<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment"># 用法线方程求解theta</span>
theta <span class="token operator">=</span> normal_equation<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>

<span class="token comment">### END CODE HERE ###</span>

plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span>theta<span class="token punctuation">)</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>




<pre><code>[&lt;matplotlib.lines.Line2D at 0x22dd1de4fd0&gt;]
</code></pre>
<p>​<br><img src="/imgs/mlhw1/output_55_1.png" alt="png"><br>​    </p>
<p>所有任务到这里就结束了，下面是对上面的数据进行任意多项式拟合的结果，你可以通过改变$K$的值来调整多项式的阶数，看看不同模型的效果(但不设的太大, $K \le 193$)。可以看到，越复杂的模型，虽然拟合数据的效果越好，但是其泛化能力就会很差，所以模型的选择应该要尽量符合实际需求。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> PolynomialFeatures
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler

<span class="token keyword">def</span> <span class="token function">PolynomialRegression</span><span class="token punctuation">(</span>degree<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">"poly"</span><span class="token punctuation">,</span>PolynomialFeatures<span class="token punctuation">(</span>degree<span class="token operator">=</span>degree<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"std_scaler"</span><span class="token punctuation">,</span>StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"lin_reg"</span><span class="token punctuation">,</span>LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> data1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> data1<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

K <span class="token operator">=</span> <span class="token number">193</span>  <span class="token comment">#可以调整K的值(0&lt;=K&lt;=193)</span>

poly_reg <span class="token operator">=</span> PolynomialRegression<span class="token punctuation">(</span>degree<span class="token operator">=</span><span class="token number">153</span><span class="token punctuation">)</span>
poly_reg<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
y_predict <span class="token operator">=</span> poly_reg<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>y_predict<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>E:\anaconda\Lib\site-packages\sklearn\utils\extmath.py:1066: RuntimeWarning: overflow encountered in square
  temp **= 2
E:\anaconda\Lib\site-packages\sklearn\utils\extmath.py:1072: RuntimeWarning: overflow encountered in square
  new_unnormalized_variance -= correction**2 / new_sample_count
E:\anaconda\Lib\site-packages\sklearn\utils\extmath.py:1072: RuntimeWarning: invalid value encountered in subtract
  new_unnormalized_variance -= correction**2 / new_sample_count
E:\anaconda\Lib\site-packages\sklearn\preprocessing\_data.py:86: RuntimeWarning: overflow encountered in square
  upper_bound = n_samples * eps * var + (n_samples * mean * eps) ** 2



---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

Cell In[42], line 18
     15 K = 193  #可以调整K的值(0&lt;=K&lt;=193)
     17 poly_reg = PolynomialRegression(degree=153)
---&gt; 18 poly_reg.fit(X,Y)
     19 y_predict = poly_reg.predict(X)
     20 plt.scatter(X,Y)


File E:\anaconda\Lib\site-packages\sklearn\pipeline.py:405, in Pipeline.fit(self, X, y, **fit_params)
    403     if self._final_estimator != &quot;passthrough&quot;:
    404         fit_params_last_step = fit_params_steps[self.steps[-1][0]]
--&gt; 405         self._final_estimator.fit(Xt, y, **fit_params_last_step)
    407 return self


File E:\anaconda\Lib\site-packages\sklearn\linear_model\_base.py:648, in LinearRegression.fit(self, X, y, sample_weight)
    644 n_jobs_ = self.n_jobs
    646 accept_sparse = False if self.positive else [&quot;csr&quot;, &quot;csc&quot;, &quot;coo&quot;]
--&gt; 648 X, y = self._validate_data(
    649     X, y, accept_sparse=accept_sparse, y_numeric=True, multi_output=True
    650 )
    652 sample_weight = _check_sample_weight(
    653     sample_weight, X, dtype=X.dtype, only_non_negative=True
    654 )
    656 X, y, X_offset, y_offset, X_scale = _preprocess_data(
    657     X,
    658     y,
   (...)
    661     sample_weight=sample_weight,
    662 )


File E:\anaconda\Lib\site-packages\sklearn\base.py:584, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, **check_params)
    582         y = check_array(y, input_name=&quot;y&quot;, **check_y_params)
    583     else:
--&gt; 584         X, y = check_X_y(X, y, **check_params)
    585     out = X, y
    587 if not no_val_X and check_params.get(&quot;ensure_2d&quot;, True):


File E:\anaconda\Lib\site-packages\sklearn\utils\validation.py:1106, in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)
   1101         estimator_name = _check_estimator_name(estimator)
   1102     raise ValueError(
   1103         f&quot;&#123;estimator_name&#125; requires y to be passed, but the target y is None&quot;
   1104     )
-&gt; 1106 X = check_array(
   1107     X,
   1108     accept_sparse=accept_sparse,
   1109     accept_large_sparse=accept_large_sparse,
   1110     dtype=dtype,
   1111     order=order,
   1112     copy=copy,
   1113     force_all_finite=force_all_finite,
   1114     ensure_2d=ensure_2d,
   1115     allow_nd=allow_nd,
   1116     ensure_min_samples=ensure_min_samples,
   1117     ensure_min_features=ensure_min_features,
   1118     estimator=estimator,
   1119     input_name=&quot;X&quot;,
   1120 )
   1122 y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)
   1124 check_consistent_length(X, y)


File E:\anaconda\Lib\site-packages\sklearn\utils\validation.py:921, in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)
    915         raise ValueError(
    916             &quot;Found array with dim %d. %s expected &lt;= 2.&quot;
    917             % (array.ndim, estimator_name)
    918         )
    920     if force_all_finite:
--&gt; 921         _assert_all_finite(
    922             array,
    923             input_name=input_name,
    924             estimator_name=estimator_name,
    925             allow_nan=force_all_finite == &quot;allow-nan&quot;,
    926         )
    928 if ensure_min_samples &gt; 0:
    929     n_samples = _num_samples(array)


File E:\anaconda\Lib\site-packages\sklearn\utils\validation.py:161, in _assert_all_finite(X, allow_nan, msg_dtype, estimator_name, input_name)
    144 if estimator_name and input_name == &quot;X&quot; and has_nan_error:
    145     # Improve the error message on how to handle missing values in
    146     # scikit-learn.
    147     msg_err += (
    148         f&quot;\n&#123;estimator_name&#125; does not accept missing values&quot;
    149         &quot; encoded as NaN natively. For supervised learning, you might want&quot;
   (...)
    159         &quot;#estimators-that-handle-nan-values&quot;
    160     )
--&gt; 161 raise ValueError(msg_err)


ValueError: Input X contains NaN.
LinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
</code></pre>
<h2 id="学习调包sklearn-Optional"><a href="#学习调包sklearn-Optional" class="headerlink" title="学习调包sklearn (Optional)"></a>学习调包sklearn (Optional)</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">"font.sans-serif"</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"SimHei"</span><span class="token punctuation">]</span> <span class="token comment">#设置字体</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">"axes.unicode_minus"</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token boolean">False</span> <span class="token comment">#该语句解决图像中的“-”负号的乱码问题</span>


data <span class="token operator">=</span> np<span class="token punctuation">.</span>loadtxt<span class="token punctuation">(</span><span class="token string">"data.txt"</span><span class="token punctuation">)</span>
<span class="token comment"># data 数据第一列为人口信息</span>
X_data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token comment"># data 数据第三列为城市峰值用电量</span>
y_data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"X shape: "</span><span class="token punctuation">,</span> X_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"y shape: "</span><span class="token punctuation">,</span> y_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre><code>X shape:  (80, 1)
y shape:  (80, 1)
</code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression
linear_reg <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>

linear_reg<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_data<span class="token punctuation">,</span> y_data<span class="token punctuation">)</span>

X_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_pred <span class="token operator">=</span> linear_reg<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>X_data<span class="token punctuation">,</span>y_data<span class="token punctuation">,</span><span class="token string">"."</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span><span class="token string">"r-"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Temperture"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"PeakDemand"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Linear Regression model predictions"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<p>​<br><img src="/imgs/mlhw1/output_60_0.png" alt="png"><br>​    </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">J&Ocean</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jiang-wu-19.github.io/2023/10/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0HW1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">https://jiang-wu-19.github.io/2023/10/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0HW1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">J&Ocean</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/">
                                    <span class="chip bg-color">线性回归</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">请我喝杯奶茶吧~</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments textarea {
        box-sizing: border-box;
        background: url("/medias/comment_bg.png") 100% 100% no-repeat;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #4cbf30;
        font-weight: 500;
        text-decoration: none;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="vcomments" class="card-content" style="display: grid">
    </div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: 'Nv6Wx6PAYH30bfcx7u0eDWHy-gzGzoHsz',
        appKey: 'IhPcpC3fDP8Ro7eaPakG2vSt',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'just go go'
    });
</script>

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2023/10/19/Snare%E5%92%8CTanner%E5%AE%89%E8%A3%85/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="Snare和Tanner安装">
                        
                        <span class="card-title">Snare和Tanner安装</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            snare和tanner软件安装
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2023-10-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB%E7%9A%84%E4%B8%9C%E8%A5%BF/" class="post-category">
                                    杂七杂八的东西
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E8%9C%9C%E7%BD%90/">
                        <span class="chip bg-color">蜜罐</span>
                    </a>
                    
                    <a href="/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/">
                        <span class="chip bg-color">信息安全</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2023/10/05/%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="矩阵计算">
                        
                        <span class="card-title">矩阵计算</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            关于矩阵求导等运算的学习
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-10-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    动手学深度学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/">
                        <span class="chip bg-color">矩阵计算</span>
                    </a>
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: J&amp;Ocean BLOG<br />'
            + '文章作者: J&amp;Ocean<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023</span>
            
            <span id="year">2023</span>
            <a href="/about" target="_blank">J&Ocean</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">161.4k</span>&nbsp;字
            
            
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2023";
                    var startMonth = "7";
                    var startDate = "2";
                    var startHour = "12";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/JIANG-Wu-19" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:wujiang0319@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=870027163" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 870027163" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/bei-wei-xiao-wu-32" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/bei-wei-xiao-wu-32" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
