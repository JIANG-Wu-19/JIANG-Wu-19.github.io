<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="ChatGPT生成内容鉴别的实现, J&amp;Ocean BLOG">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>ChatGPT生成内容鉴别的实现 | J&amp;Ocean BLOG</title>
    <link rel="icon" type="image/x-icon, image/vnd.microsoft.icon" href="/favicon.ico">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 6.3.0"></head>



   <style>
    body{
       background-image: url(https://github.com/JIANG-Wu-19/JIANG-Wu-19/blob/master/99759389_p0.png?raw=true);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.ico" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">J&amp;Ocean BLOG</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.ico" class="logo-img circle responsive-img">
        
        <div class="logo-name">J&amp;Ocean BLOG</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/23.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">ChatGPT生成内容鉴别的实现</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/NLP/">
                                <span class="chip bg-color">NLP</span>
                            </a>
                        
                            <a href="/tags/Python/">
                                <span class="chip bg-color">Python</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%9A%91%E6%9C%9F%E5%AE%9E%E4%B9%A0/" class="post-category">
                                暑期实习
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-08-06
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    8.6k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    34 分
                </div>
                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p>题目链接：<a target="_blank" rel="noopener" href="https://challenge.xfyun.cn/topic/info?type=text-detector&option=phb">ChatGPT生成文本检测器</a></p>
<p>友情链接：<a target="_blank" rel="noopener" href="https://datawhaler.feishu.cn/docx/OQjWdEuAZo2nTSxHmT6crhZ2nmf">Datawhale-NLP实践</a></p>
<p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/JIANG-Wu-19/NLP_project">NLP_project</a></p>
<h2 id="跑通一个baseline"><a href="#跑通一个baseline" class="headerlink" title="跑通一个baseline"></a>跑通一个baseline</h2><p>这次的baseline使用<strong>手工确定提取文本特征</strong>，在第四点中有体现</p>
<ol>
<li><p><strong>导入库</strong>：开始时导入必要的库，包括numpy、pandas和scikit-learn的LogisticRegression。</p>
</li>
<li><p><strong>加载数据</strong>：加载两个CSV文件——‘train.csv’和’test.csv’，并分别存储在pandas的DataFrame ‘train_data’和’test_data’中。</p>
</li>
<li><p><strong>数据预处理</strong>：对’train_data’和’test_data’的’content’列应用了一些预处理步骤。它使用lambda函数从’content’列中的每个字符串中移除第一个和最后一个字符，也就是移除“[”和“]”</p>
</li>
<li><p><strong>特征工程</strong>：定义一个名为’simple_feature(s)’的函数，它接受一个字符串’s’作为输入，并基于输入字符串的特性返回一个numpy数组作为特征，特征都是人为的选取所以效果并不是特别好这些特征包括：</p>
<ul>
<li>原始字符串的长度。</li>
<li>字符串中字符的数量。</li>
<li>字符串中唯一字符的数量。</li>
<li>字符串中重复字符的数量。</li>
<li>唯一字符数占总字符数的比例。</li>
<li>字符串中字符频率的最大值。</li>
<li>字符串中字符频率的最小值。</li>
<li>字符串中字符频率的平均值。</li>
<li>字符串中字符频率的标准差。</li>
<li>字符串中字符频率的极差（最大值与最小值之间的差值）。</li>
</ul>
</li>
<li><p><strong>生成训练和测试特征</strong>：使用<code>apply</code>方法将’simple_feature’函数应用于’train_data’和’test_data’的’content’列中的每个字符串。得到的特征被垂直堆叠以创建numpy数组’train_feature’和’test_feature’。</p>
</li>
<li><p><strong>模型训练</strong>：通过调用scikit-learn的<code>LogisticRegression()</code>来初始化一个逻辑回归模型’m’。然后，使用<code>fit</code>方法将训练特征’train_feature’和’train_data’中对应的’label’列用于训练模型。</p>
</li>
<li><p><strong>进行预测</strong>：训练好的模型使用<code>predict</code>方法对测试数据进行预测，得到测试集的标签。</p>
</li>
<li><p><strong>将结果保存为CSV</strong>：将预测的标签添加到’test_data’的’label’列中，然后创建一个只包含’name’和’label’列的新DataFrame。最后，将这个DataFrame保存为名为’simple.csv’的CSV文件，可以用于提交或进一步分析。</p>
</li>
</ol>
<p>baseline跑出来的分数中规中矩，只有0.85+，还需要进行调整</p>
<p>详细见附录</p>
<h2 id="冲榜尝试，upper的产生"><a href="#冲榜尝试，upper的产生" class="headerlink" title="冲榜尝试，upper的产生"></a>冲榜尝试，upper的产生</h2><p>upper基于TF-IDF，简单了解一下TF-IDF</p>
<h3 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h3><p>TF-IDF (Term Frequency-Inverse Document Frequency) 是一种在文本挖掘和信息检索中常用的特征表示方法，用于衡量一个词语对于一个文档集合中某个文档的重要程度。</p>
<p>TF-IDF 特征由两部分组成：Term Frequency (TF) 和 Inverse Document Frequency (IDF)。</p>
<ol>
<li><p>**Term Frequency (TF)**：指定词语在文档中出现的频率。它表示一个词在文档中的重要程度。一般情况下，一个词在文档中出现的次数越多，它对文档的内容表达越重要。</p>
<p>TF &#x3D; (词语在文档中出现的次数) &#x2F; (文档中总词语数)</p>
</li>
<li><p>**Inverse Document Frequency (IDF)**：指定词语在整个文档集合中的重要程度。它是通过对所有文档计算某个词的出现频率，然后取其倒数来计算的。IDF 的目的是降低在多个文档中频繁出现的常见词的权重，增加对于少数文档中出现但对于整个文档集合较为重要的词的权重。</p>
<p>IDF &#x3D; log(文档集合中的文档总数 &#x2F; 含有该词的文档数 + 1)</p>
</li>
</ol>
<p>最终的 TF-IDF 特征是将 TF 和 IDF 相乘得到的。TF-IDF 特征考虑了一个词在当前文档中的重要性（TF），以及它在整个文档集合中的全局重要性（IDF）。因此，TF-IDF 特征能够在文本分类和信息检索任务中更好地捕捉每个词在文档中的信息价值，从而在构建特征表示时更好地区分不同的文档。</p>
<h3 id="upper的思路"><a href="#upper的思路" class="headerlink" title="upper的思路"></a>upper的思路</h3><ol>
<li><p><strong>导入库</strong>：开始时导入所需的库，包括pandas、sklearn的LogisticRegression类、TfidfVectorizer类以及一些评估指标相关的库。</p>
</li>
<li><p><strong>加载数据</strong>：加载两个CSV文件——‘train.csv’和’test.csv’，并将它们分别存储在pandas的DataFrame ‘train_data’和’test_data’中。</p>
</li>
<li><p><strong>数据预处理</strong>：对’train_data’和’test_data’的’content’列应用了一些预处理步骤。它使用lambda函数从’content’列中的每个字符串中移除第一个和最后一个字符。</p>
</li>
<li><p><strong>TF-IDF特征提取</strong>：</p>
<ul>
<li>使用TfidfVectorizer类来将文本内容转换为TF-IDF向量表示。</li>
<li>尝试了三种不同的TF-IDF参数设置：<ul>
<li>第1种参数：token_pattern&#x3D;r’\w{1}’，max_features&#x3D;2000。token_pattern指定了用于提取词语的正则表达式，r’\w{1}’表示提取长度为1的单词。max_features设置为2000表示最多选择2000个最重要的特征词。</li>
<li>第2种参数：token_pattern&#x3D;r’\w{1}’，max_features&#x3D;5000。max_features设置为5000表示最多选择5000个最重要的特征词。</li>
<li>第3种参数：token_pattern&#x3D;r’\w{1}’，max_features&#x3D;5000，ngram_range&#x3D;(1,2)。ngram_range&#x3D;(1,2)表示同时提取单个词和二元（两个词）的组合作为特征。</li>
</ul>
</li>
<li>对于每种参数设置，分别将训练集和测试集的文本内容转换为TF-IDF向量表示。</li>
</ul>
</li>
<li><p><strong>模型训练和评估</strong>：</p>
<ul>
<li>对于每种TF-IDF参数设置，使用交叉验证（cross_val_predict）对逻辑回归模型进行评估，以得到更稳定的性能评估结果。</li>
<li>使用<code>cross_val_predict</code>方法对训练集的TF-IDF向量和对应的标签进行交叉验证预测，然后通过classification_report函数输出分类结果的评估报告，包括精确度、召回率、F1-score等指标。</li>
</ul>
</li>
<li><p><strong>模型训练和预测</strong>：</p>
<ul>
<li>选择其中一种TF-IDF参数设置（这里使用第3种参数）来训练逻辑回归模型。</li>
<li>使用训练好的模型对测试集的TF-IDF向量进行预测，并将预测结果保存在’test_data’的’label’列中。</li>
</ul>
</li>
<li><p><strong>保存结果为CSV文件</strong>：</p>
<ul>
<li>将测试集的’name’和’label’列保存为名为’tfidf.csv’的CSV文件，用于后续的提交或分析。</li>
</ul>
</li>
</ol>
<p>总体来说，使用TF-IDF特征提取方法和逻辑回归模型进行文本分类任务，并通过交叉验证来评估模型的性能。通过尝试不同的TF-IDF参数设置，可以找到最佳的特征提取策略，以获得更好的分类结果。</p>
<p>对于upper，冲榜的分数能够达到0.91+，但是这还不够，可以考虑之前使用过的BERT模型进行分类</p>
<p>详细代码见附录</p>
<p>后续尝试方向：</p>
<ul>
<li>调用BERT模型进行鉴别</li>
<li>调用大模型进行鉴别</li>
</ul>
<h2 id="使用BERT模型进行分类"><a href="#使用BERT模型进行分类" class="headerlink" title="使用BERT模型进行分类"></a>使用BERT模型进行分类</h2><p>简单了解一下BERT模型</p>
<h3 id="BERT模型"><a href="#BERT模型" class="headerlink" title="BERT模型"></a>BERT模型</h3><p>BERT（Bidirectional Encoder Representations from Transformers） 是一种预训练的自然语言处理模型，由Google研发并于2018年发布。BERT采用了<strong>Transformer网络结构</strong>，通过大规模无监督训练从而学习到单词或字符级别的语言表示。相比于传统的基于循环神经网络的模型，BERT采用了双向编码器（Bidirectional Encoder）的思想，可以同时利用上下文中的信息来理解单词的语义和含义。</p>
<p>BERT的预训练过程分为两个阶段：<strong>Masked Language Model（MLM）</strong>和<strong>Next Sentence Prediction（NSP）</strong>。在MLM阶段，BERT会随机遮盖输入文本中的部分单词，并尝试预测这些遮盖的单词是什么。在NSP阶段，BERT会输入两个句子，并预测这两个句子是否是连续的。</p>
<p>预训练后，BERT可以通过微调（Fine-tuning）的方式在特定任务上进行训练，例如文本分类、命名实体识别等。通过微调，BERT可以根据不同任务的数据进行适应性学习，提取有关任务的上下文相关特征，从而更好地完成特定的自然语言处理任务。</p>
<p>BERT的出现填补了自然语言处理领域在预训练模型上的空白，它在多个基准数据集上取得了显著的性能提升，并且对于多种自然语言处理任务都具有泛化能力。BERT的成功也促进了许多后续的预训练模型的发展，为自然语言处理的研究和应用提供了重要的推动力。</p>
<p>BERT模型的结构主要由Transformer网络组成，它由多个编码器层叠加而成。每个编码器层由两个子层组成，分别是多头自注意力机制（Multi-Head Self-Attention）和前馈神经网络（Feed-Forward Neural Network）。下面我们逐步解释BERT模型的结构和各个组件的作用。</p>
<ol>
<li><p>输入表示：BERT的输入表示采用了词嵌入和位置编码的结合。首先，对输入的文本进行分词处理，然后将每个分词映射为一个固定维度的词向量。位置编码会为每个词向量附加一个位置信息，以捕捉单词在句子中的相对位置关系。</p>
</li>
<li><p>编码器层：BERT模型通常包含多个相同结构的编码器层，每个编码器层都由两个子层组成。</p>
<ul>
<li>多头自注意力机制（Multi-Head Self-Attention）：在这个子层中，输入的序列经过一系列的自注意力计算，从而学习到每个单词与其他单词之间的相互作用和关联。通过引入多个注意力头，可以并行地学习多个表示，增加模型的泛化能力。</li>
<li>前馈神经网络（Feed-Forward Neural Network）：在这个子层中，每个位置的隐藏表示会经过两层全连接网络进行非线性变换，增强模型的表示能力。前馈神经网络采用了激活函数（如ReLU）来引入非线性。</li>
</ul>
</li>
<li><p>预训练目标：</p>
<ul>
<li>遮盖语言模型（Masked Language Model，MLM）：BERT采用遮盖部分输入单词的方式，然后通过预测被遮盖单词的方式进行训练。这使得模型能够学习到单词之间的上下文信息，从而更好地理解句子。</li>
<li>下一句预测（Next Sentence Prediction，NSP）：BERT的预训练还包括判断两个句子之间是否连续的任务。通过这个任务，模型可以学习到句子之间的语义关系和连接方式。</li>
</ul>
</li>
</ol>
<p>BERT模型的核心思想是通过大规模的无监督预训练，学习到通用的句子表示，然后通过微调的方式在具体任务上进行训练。预训练过程使得BERT模型具备了更好的语义理解能力和句子关系建模能力，从而在各种自然语言处理任务中取得了显著的性能提升。</p>
<h3 id="BERT的思路"><a href="#BERT的思路" class="headerlink" title="BERT的思路"></a>BERT的思路</h3><p>关于使用BERT模型，之前的[项目](<a target="_blank" rel="noopener" href="https://github.com/JIANG-Wu-19/NLP_project/tree/master/Text">https://github.com/JIANG-Wu-19/NLP_project/tree/master/Text</a> classification and keyword extraction based on abstracts)已经实现过，基于BERT模型判断文本是否属于医学论文，也就是说可以依靠原有代码，在原有代码的基础上进行相关改动就可以实现了，关于BERT模型进行文本分类脚本的实现，可以在《<a href="https://jiang-wu-19.github.io/2023/07/30/upper%E7%9A%84%E5%AE%9E%E7%8E%B0/">upper的实现 | J&amp;Ocean BLOG</a>》这篇blog中进一步了解</p>
<p>BERT模型的训练可以在本地实现，考虑到笔者的配置有限，将batch_size设置为10，运行时只需要使用3.8G的显存。</p>
<p>BERT跑出来的结果还不错，高于原有的进阶分数，达到0.93+</p>
<h2 id="不死心，仍要使用大模型的API"><a href="#不死心，仍要使用大模型的API" class="headerlink" title="不死心，仍要使用大模型的API"></a>不死心，仍要使用大模型的API</h2><p>事实证明，API最多只能回答一些生成式的问题，也许是API背后的模型是综合类型的，并没有经过二分类的fine-tune，代码确实写好了，但是由于鉴别的文本相当冗长，每进行一次request耗费大量的tokens还有时间</p>
<p><del>对API的调用感兴趣的可以看一看失败的的代码</del></p>
<h2 id="选择ernie模型，取得阶段性小胜利"><a href="#选择ernie模型，取得阶段性小胜利" class="headerlink" title="选择ernie模型，取得阶段性小胜利"></a>选择ernie模型，取得阶段性小胜利</h2><p>使用paddle框架和ernie模型</p>
<h3 id="paddlepaddle和"><a href="#paddlepaddle和" class="headerlink" title="paddlepaddle和"></a>paddlepaddle和</h3><p>PaddlePaddle（百度飞桨）是百度开发的开源深度学习框架，旨在为科研人员和工程师提供高效、灵活、全面的深度学习平台。它在深度学习领域具有广泛的应用，特别在自然语言处理、计算机视觉、语音识别等领域表现出色。以下是PaddlePaddle框架的一些关键特点和组成部分的简要介绍：</p>
<ol>
<li><p><strong>动态图和静态图支持</strong>：PaddlePaddle支持动态图和静态图两种计算模式。动态图适用于快速原型设计和交互式调试，而静态图则可以优化计算图以提高性能和效率。</p>
</li>
<li><p><strong>高性能优化</strong>：PaddlePaddle针对多种硬件和平台进行了高性能优化，包括CPU、GPU、FPGA等。它采用了诸如自动混合精度、异步数据加载等技术，以提高训练和推理的速度。</p>
</li>
<li><p><strong>多样的模型库和工具</strong>：PaddlePaddle提供了丰富的预训练模型和模型库，涵盖自然语言处理、计算机视觉、推荐系统等多个领域。同时，它还提供了数据处理、模型评估、可视化等一系列工具，方便用户进行全面的深度学习任务。</p>
</li>
<li><p><strong>易用性和灵活性</strong>：PaddlePaddle设计了简单易用的API，使得初学者可以快速上手。同时，它也提供了灵活的自定义功能，以满足高级用户的需求。</p>
</li>
<li><p><strong>分布式训练和部署</strong>：PaddlePaddle支持分布式训练，可以在多个机器和设备上并行进行训练。此外，它还提供了模型转换和部署工具，使模型部署更加便捷。</p>
</li>
<li><p><strong>自然语言处理工具包</strong>：PaddlePaddle自然语言处理工具包（PaddleNLP）为处理文本数据提供了丰富的功能，包括预训练模型、分词、命名实体识别、文本分类等。</p>
</li>
<li><p><strong>社区支持和文档</strong>：PaddlePaddle有活跃的社区，提供了丰富的教程、文档和示例代码，帮助用户更好地了解和使用框架。</p>
</li>
</ol>
<h3 id="paddleNLP"><a href="#paddleNLP" class="headerlink" title="paddleNLP"></a>paddleNLP</h3><p>PaddleNLP是百度飞桨（PaddlePaddle）深度学习框架的自然语言处理（NLP）工具包，专门为处理文本数据和解决自然语言处理问题而设计。它提供了丰富的预训练模型、数据处理工具和任务特定的API，使得NLP任务的开发和研究更加便捷和高效。以下是PaddleNLP的一些主要特点和组成部分的简要介绍：</p>
<ol>
<li><p><strong>预训练模型库</strong>：PaddleNLP提供了丰富的预训练模型，包括BERT、ERNIE、RoBERTa、GPT等。这些模型在大规模文本数据上进行预训练，可以用于多种NLP任务的迁移学习和微调。</p>
</li>
<li><p><strong>任务特定API</strong>：PaddleNLP为常见的NLP任务（如文本分类、序列标注、句子对匹配等）提供了专门的API接口，使得模型的训练和评估变得更加简单。开发者可以直接使用这些API来完成各种任务，无需从头开始构建模型。</p>
</li>
<li><p><strong>分词和数据处理工具</strong>：PaddleNLP提供了强大的分词和数据处理工具，用于将原始文本数据转换为模型可以处理的格式。这些工具支持中文、英文等多种语言，帮助用户有效地准备数据集。</p>
</li>
<li><p><strong>模型可解释性工具</strong>：PaddleNLP还提供了模型可解释性工具，可以帮助用户理解模型的预测结果，分析哪些部分影响了模型的决策。</p>
</li>
<li><p><strong>多语言支持</strong>：PaddleNLP支持多种语言，包括中文和英文，使其适用于全球范围的NLP研究和应用。</p>
</li>
<li><p><strong>与PaddlePaddle集成</strong>：PaddleNLP与PaddlePaddle深度学习框架无缝集成，用户可以直接将PaddleNLP的模型和功能与PaddlePaddle的其他组件结合使用。</p>
</li>
</ol>
<h3 id="Ernie模型"><a href="#Ernie模型" class="headerlink" title="Ernie模型"></a>Ernie模型</h3><p>ERNIE（Enhanced Representation through kNowledge IntEgration）是一种基于Transformer架构的预训练语言模型，由百度研究团队开发。ERNIE的网络架构与Transformer的基本结构类似，但在细节上进行了一些创新和改进，以适应多领域、多语种的知识融合。以下是ERNIE模型的网络架构的简要介绍：</p>
<ol>
<li><p><strong>Transformer基本结构</strong>：ERNIE模型采用了Transformer架构，它由多个编码器层和解码器层组成。每个编码器和解码器层包含自注意力机制和前馈神经网络。自注意力机制有助于模型捕捉输入序列中不同位置之间的依赖关系。</p>
</li>
<li><p><strong>多头注意力</strong>：类似于Transformer，ERNIE的注意力机制也采用了多头注意力。这使得模型可以在不同的注意力头上并行学习不同的信息，从而更好地捕捉序列中的各种关系。</p>
</li>
<li><p><strong>连续字词表示</strong>：ERNIE引入了连续字词表示，对于中文等没有明确分词边界的语言尤为重要。它通过将字母、音节等形式进行建模，以更好地捕获复杂的语言结构。</p>
</li>
<li><p><strong>双向语言模型预训练</strong>：ERNIE使用了双向语言模型（Bidirectional Language Model，BiLM）进行预训练。这意味着模型在预测当前词语时，可以利用前面和后面的词语信息，从而获得更好的上下文表示。</p>
</li>
<li><p><strong>多领域、多语种知识融合</strong>：ERNIE的创新之一是将多领域、多语种的知识融合到预训练中。它通过同时在多个领域和多种语言的数据上进行预训练，使模型能够学习丰富的知识和表示。</p>
</li>
<li><p><strong>多任务学习</strong>：ERNIE在预训练和微调阶段使用了多任务学习。这意味着模型在同一时间可以同时学习多个任务，从而增强模型的泛化能力和效果。</p>
</li>
</ol>
<h3 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h3><p>使用PaddlePaddle深度学习框架和PaddleNLP自然语言处理工具包构建文本分类模型。该模型用于将文本分类为两个类别，并通过训练数据进行模型训练和验证，然后使用该模型对测试数据进行分类，并生成一个提交文件。</p>
<p>以下是代码的详细分析：</p>
<ol>
<li><p><strong>导入库</strong>：首先，导入了必要的库，包括NumPy（用于数值计算）、Pandas（用于数据分析）、tqdm（用于显示进度条）、PaddlePaddle（深度学习框架）、PaddleNLP（用于自然语言处理）、以及其他用于数据加载、模型训练等的库。</p>
</li>
<li><p><strong>加载数据</strong>：使用Pandas库从CSV文件中加载训练数据和测试数据。</p>
</li>
<li><p><strong>载入模型与分词器</strong>：使用<code>AutoModelForSequenceClassification</code>从预训练的ernie-3.0-mini-zh模型中加载序列分类模型，并设置分类类别数为2。同样，使用<code>AutoTokenizer</code>加载相应的分词器。</p>
</li>
<li><p><strong>定义优化器和损失函数</strong>：定义AdamW优化器和交叉熵损失函数。</p>
</li>
<li><p><strong>划分训练集和验证集</strong>：使用<code>train_test_split</code>将训练数据划分为训练集和验证集。</p>
</li>
<li><p><strong>数据处理与加载</strong>：将数据转换为适合数据加载器的格式，并创建数据加载器。训练数据可以随机打乱，以便模型更好地学习。注意，这里的数据加载器用的是PaddlePaddle的<code>DataLoader</code>，可以在训练过程中并行加载数据，提高训练效率。</p>
</li>
<li><p><strong>模型训练循环</strong>：使用循环进行模型训练，训练多个epochs。在每个epoch内，模型会被切换到训练模式，然后遍历训练数据批次进行训练。具体步骤包括：</p>
<ul>
<li>将文本数据转换为模型可以处理的格式，包括使用分词器进行分词并填充到固定长度。</li>
<li>将数据输入模型，得到预测结果。</li>
<li>计算预测结果与真实标签之间的交叉熵损失。</li>
<li>执行反向传播以计算梯度。</li>
<li>使用优化器更新模型参数。</li>
</ul>
</li>
<li><p><strong>验证过程</strong>：在每个epoch结束后，切换模型为验证模式，并使用验证数据集计算验证损失。同样，将数据转换为模型可以处理的格式，进行前向传播计算，并计算验证损失。</p>
</li>
<li><p><strong>保存最佳模型</strong>：如果当前epoch的准确率优于之前的最佳准确率，将模型和优化器参数保存为检查点文件。</p>
</li>
<li><p><strong>模型保存</strong>：在所有epoch训练完成后，将最终模型和优化器参数保存。</p>
</li>
<li><p><strong>模型推理</strong>：定义了一个用于对输入文本进行预测的函数<code>infer</code>，该函数将输入文本转换为模型可以处理的格式，然后使用训练好的模型进行预测，并返回预测结果。</p>
</li>
<li><p><strong>对测试数据进行预测</strong>：使用上述<code>infer</code>函数将测试数据的文本送入模型，得到预测结果。然后创建一个包含预测结果的新数据表，准备生成提交文件。</p>
</li>
<li><p><strong>生成提交文件</strong>：将包含预测结果的测试数据表保存为CSV文件，用于提交到竞赛平台。</p>
</li>
</ol>
<p>在使用Ernie模型的时候，为了加快速度，放弃了本地环境，使用了百度AI Studio云环境进行训练，每一轮训练时间为60s，验证时间为6s</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="baseline-py"><a href="#baseline-py" class="headerlink" title="baseline.py"></a>baseline.py</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression

<span class="token comment"># Load data</span>
train_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'train.csv'</span><span class="token punctuation">)</span>
test_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'test.csv'</span><span class="token punctuation">)</span>

train_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token comment"># Get the feature</span>
<span class="token keyword">def</span> <span class="token function">simple_feature</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        s <span class="token operator">=</span> <span class="token string">'123 123'</span>

    w <span class="token operator">=</span> s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 统计字符出现次数</span>
    w_count <span class="token operator">=</span> np<span class="token punctuation">.</span>bincount<span class="token punctuation">(</span>w<span class="token punctuation">)</span>
    w_count <span class="token operator">=</span> w_count<span class="token punctuation">[</span>w_count <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">]</span>

    <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>

        <span class="token builtin">len</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 原始字符长度</span>
        <span class="token builtin">len</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 字符个数</span>
        <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 不重复字符个数</span>
        <span class="token builtin">len</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 字符个数 - 不重复字符个数</span>
        <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 不重复字符个数占比</span>

        np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>w_count<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 字符的频率的最大值</span>
        np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>w_count<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 字符的频率的最小值</span>
        np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>w_count<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 字符的频率的平均值</span>
        np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>w_count<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 字符的频率的方差</span>
        np<span class="token punctuation">.</span>ptp<span class="token punctuation">(</span>w_count<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 字符的频率的极差</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>


train_feature <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>simple_feature<span class="token punctuation">)</span>
test_feature <span class="token operator">=</span> test_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>simple_feature<span class="token punctuation">)</span>

train_feature <span class="token operator">=</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>train_feature<span class="token punctuation">.</span>values<span class="token punctuation">)</span>
test_feature <span class="token operator">=</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>test_feature<span class="token punctuation">.</span>values<span class="token punctuation">)</span>

<span class="token comment"># 模型训练</span>
m <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
m<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_feature<span class="token punctuation">,</span> train_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 生成测试集提交结果</span>
test_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> m<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_feature<span class="token punctuation">)</span>
test_data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'simple.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="upper-py"><a href="#upper-py" class="headerlink" title="upper.py"></a>upper.py</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_predict
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> classification_report

train_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'train.csv'</span><span class="token punctuation">)</span>
test_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'test.csv'</span><span class="token punctuation">)</span>

train_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 第1种tfidf参数</span>
tfidf <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>token_pattern<span class="token operator">=</span><span class="token string">r'\w&#123;1&#125;'</span><span class="token punctuation">,</span> max_features<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">)</span>
train_tfidf <span class="token operator">=</span> tfidf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>train_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_tfidf <span class="token operator">=</span> tfidf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>test_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>classification_report<span class="token punctuation">(</span>
    cross_val_predict<span class="token punctuation">(</span>
        LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        train_tfidf<span class="token punctuation">,</span>
        train_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    train_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    digits<span class="token operator">=</span><span class="token number">4</span>
<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 第2种tfidf参数</span>
tfidf <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>token_pattern<span class="token operator">=</span><span class="token string">r'\w&#123;1&#125;'</span><span class="token punctuation">,</span> max_features<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">)</span>
train_tfidf <span class="token operator">=</span> tfidf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>train_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_tfidf <span class="token operator">=</span> tfidf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>test_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>classification_report<span class="token punctuation">(</span>
    cross_val_predict<span class="token punctuation">(</span>
        LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        train_tfidf<span class="token punctuation">,</span>
        train_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    train_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    digits<span class="token operator">=</span><span class="token number">4</span>
<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 第3种tfidf参数</span>
tfidf <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>token_pattern<span class="token operator">=</span><span class="token string">r'\w&#123;1&#125;'</span><span class="token punctuation">,</span> max_features<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">,</span> ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
train_tfidf <span class="token operator">=</span> tfidf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>train_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test_tfidf <span class="token operator">=</span> tfidf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>test_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>classification_report<span class="token punctuation">(</span>
    cross_val_predict<span class="token punctuation">(</span>
        LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        train_tfidf<span class="token punctuation">,</span>
        train_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span><span class="token punctuation">,</span>
    train_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    digits<span class="token operator">=</span><span class="token number">4</span>
<span class="token punctuation">)</span><span class="token punctuation">)</span>


m <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
m<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_tfidf<span class="token punctuation">,</span>
    train_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

test_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> m<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_tfidf<span class="token punctuation">)</span>
test_data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">,</span> <span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'tfidf.csv'</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>

<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="bert-py"><a href="#bert-py" class="headerlink" title="bert.py"></a>bert.py</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 导入前置依赖</span>
<span class="token keyword">import</span> os
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader
<span class="token comment"># 用于加载bert模型的分词器</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer
<span class="token comment"># 用于加载bert模型</span>
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertModel
<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path





batch_size <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment"># 文本的最大长度</span>
text_max_length <span class="token operator">=</span> <span class="token number">128</span>
<span class="token comment"># 总训练的epochs数，我只是随便定义了个数</span>
epochs <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment"># 学习率</span>
lr <span class="token operator">=</span> <span class="token number">3e-5</span>
<span class="token comment"># 取多少训练集的数据作为验证集</span>
validation_ratio <span class="token operator">=</span> <span class="token number">0.1</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>

<span class="token comment"># 每多少步，打印一次loss</span>
log_per_step <span class="token operator">=</span> <span class="token number">50</span>

<span class="token comment"># 数据集所在位置</span>
dataset_dir <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">"./ChatGPT生成文本检测器"</span><span class="token punctuation">)</span>
os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>dataset_dir<span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>dataset_dir<span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">''</span>

<span class="token comment"># 模型存储路径</span>
model_dir <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">"./model/bert_checkpoints"</span><span class="token punctuation">)</span>
<span class="token comment"># 如果模型目录不存在，则创建一个</span>
os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">''</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Device:"</span><span class="token punctuation">,</span> device<span class="token punctuation">)</span>

<span class="token comment"># 读取数据集，进行数据处理</span>

pd_train_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'train.csv'</span><span class="token punctuation">)</span>
pd_train_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token operator">=</span>pd_train_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span>

test_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'test.csv'</span><span class="token punctuation">)</span>
test_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token operator">=</span>test_data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span>


<span class="token comment"># 从训练集中随机采样测试集</span>
validation_data <span class="token operator">=</span> pd_train_data<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>frac<span class="token operator">=</span>validation_ratio<span class="token punctuation">)</span>
train_data <span class="token operator">=</span> pd_train_data<span class="token punctuation">[</span><span class="token operator">~</span>pd_train_data<span class="token punctuation">.</span>index<span class="token punctuation">.</span>isin<span class="token punctuation">(</span>validation_data<span class="token punctuation">.</span>index<span class="token punctuation">)</span><span class="token punctuation">]</span>


<span class="token comment"># 构建Dataset</span>
<span class="token keyword">class</span> <span class="token class-name">MyDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MyDataset<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode
        <span class="token comment"># 拿到对应的数据</span>
        <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>dataset <span class="token operator">=</span> train_data
        <span class="token keyword">elif</span> mode <span class="token operator">==</span> <span class="token string">'validation'</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>dataset <span class="token operator">=</span> validation_data
        <span class="token keyword">elif</span> mode <span class="token operator">==</span> <span class="token string">'test'</span><span class="token punctuation">:</span>
            <span class="token comment"># 如果是测试模式，则返回内容和uuid。拿uuid做target主要是方便后面写入结果。</span>
            self<span class="token punctuation">.</span>dataset <span class="token operator">=</span> test_data
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> Exception<span class="token punctuation">(</span><span class="token string">"Unknown mode &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>mode<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 取第index条</span>
        data <span class="token operator">=</span> self<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        <span class="token comment"># 取其内容</span>
        text <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span>
        <span class="token comment"># 根据状态返回内容</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>mode <span class="token operator">==</span> <span class="token string">'test'</span><span class="token punctuation">:</span>
            <span class="token comment"># 如果是test，将uuid做为target</span>
            label <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            label <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>
        <span class="token comment"># 返回内容和label</span>
        <span class="token keyword">return</span> text<span class="token punctuation">,</span> label

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>


train_dataset <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span>
validation_dataset <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span><span class="token string">'validation'</span><span class="token punctuation">)</span>

train_dataset<span class="token punctuation">.</span>__getitem__<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 获取Bert预训练模型</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>


<span class="token comment"># 接着构造我们的Dataloader。</span>
<span class="token comment"># 我们需要定义一下collate_fn，在其中完成对句子进行编码、填充、组装batch等动作：</span>
<span class="token keyword">def</span> <span class="token function">collate_fn</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    将一个batch的文本句子转成tensor，并组成batch。
    :param batch: 一个batch的句子，例如: [('推文', target), ('推文', target), ...]
    :return: 处理后的结果，例如：
             src: &#123;'input_ids': tensor([[ 101, ..., 102, 0, 0, ...], ...]), 'attention_mask': tensor([[1, ..., 1, 0, ...], ...])&#125;
             target：[1, 1, 0, ...]
    """</span>
    text<span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>batch<span class="token punctuation">)</span>
    text<span class="token punctuation">,</span> label <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span>

    <span class="token comment"># src是要送给bert的，所以不需要特殊处理，直接用tokenizer的结果即可</span>
    <span class="token comment"># padding='max_length' 不够长度的进行填充</span>
    <span class="token comment"># truncation=True 长度过长的进行裁剪</span>
    src <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'max_length'</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span>text_max_length<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> src<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>label<span class="token punctuation">)</span>


train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span>
validation_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>validation_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span>

inputs<span class="token punctuation">,</span> targets <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"inputs:"</span><span class="token punctuation">,</span> inputs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"targets:"</span><span class="token punctuation">,</span> targets<span class="token punctuation">)</span>


<span class="token comment"># 定义预测模型，该模型由bert模型加上最后的预测层组成</span>
<span class="token keyword">class</span> <span class="token class-name">MyModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MyModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 加载bert模型</span>
        self<span class="token punctuation">.</span>bert <span class="token operator">=</span> BertModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-uncased'</span><span class="token punctuation">,</span> mirror<span class="token operator">=</span><span class="token string">'tuna'</span><span class="token punctuation">)</span>

        <span class="token comment"># 最后的预测层</span>
        self<span class="token punctuation">.</span>predictor <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">768</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        :param src: 分词后的推文数据
        """</span>

        <span class="token comment"># 将src直接序列解包传入bert，因为bert和tokenizer是一套的，所以可以这么做。</span>
        <span class="token comment"># 得到encoder的输出，用最前面[CLS]的输出作为最终线性层的输入</span>
        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>bert<span class="token punctuation">(</span><span class="token operator">**</span>src<span class="token punctuation">)</span><span class="token punctuation">.</span>last_hidden_state<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

        <span class="token comment"># 使用线性层来做最终的预测</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>predictor<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>


model <span class="token operator">=</span> MyModel<span class="token punctuation">(</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 定义出损失函数和优化器。这里使用Binary Cross Entropy：</span>
criteria <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>


<span class="token comment"># 由于inputs是字典类型的，定义一个辅助函数帮助to(device)</span>
<span class="token keyword">def</span> <span class="token function">to_device</span><span class="token punctuation">(</span>dict_tensors<span class="token punctuation">)</span><span class="token punctuation">:</span>
    result_tensors <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
    <span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> dict_tensors<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        result_tensors<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    <span class="token keyword">return</span> result_tensors


<span class="token comment"># 定义一个验证方法，获取到验证集的精准率和loss</span>
<span class="token keyword">def</span> <span class="token function">validate</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    total_loss <span class="token operator">=</span> <span class="token number">0.</span>
    total_correct <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> inputs<span class="token punctuation">,</span> targets <span class="token keyword">in</span> validation_loader<span class="token punctuation">:</span>
        inputs<span class="token punctuation">,</span> targets <span class="token operator">=</span> to_device<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">,</span> targets<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criteria<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> targets<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        total_loss <span class="token operator">+=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

        correct_num <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>outputs <span class="token operator">>=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        total_correct <span class="token operator">+=</span> correct_num

    <span class="token keyword">return</span> total_correct <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>validation_dataset<span class="token punctuation">)</span><span class="token punctuation">,</span> total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>validation_dataset<span class="token punctuation">)</span>


<span class="token comment"># 首先将模型调成训练模式</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 清空一下cuda缓存</span>
<span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>empty_cache<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 定义几个变量，帮助打印loss</span>
total_loss <span class="token operator">=</span> <span class="token number">0.</span>
<span class="token comment"># 记录步数</span>
step <span class="token operator">=</span> <span class="token number">0</span>

<span class="token comment"># 记录在验证集上最好的准确率</span>
best_accuracy <span class="token operator">=</span> <span class="token number">0</span>

<span class="token comment"># 开始训练</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 从batch中拿到训练数据</span>
        inputs<span class="token punctuation">,</span> targets <span class="token operator">=</span> to_device<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">,</span> targets<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        <span class="token comment"># 传入模型进行前向传递</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        <span class="token comment"># 计算损失</span>
        loss <span class="token operator">=</span> criteria<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> targets<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

        total_loss <span class="token operator">+=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
        step <span class="token operator">+=</span> <span class="token number">1</span>

        <span class="token keyword">if</span> step <span class="token operator">%</span> log_per_step <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch &#123;&#125;/&#123;&#125;, Step: &#123;&#125;/&#123;&#125;, total loss:&#123;:.4f&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> epochs<span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                                       total_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
            total_loss <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token keyword">del</span> inputs<span class="token punctuation">,</span> targets

    <span class="token comment"># 一个epoch后，使用过验证集进行验证</span>
    accuracy<span class="token punctuation">,</span> validation_loss <span class="token operator">=</span> validate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch &#123;&#125;, accuracy: &#123;:.4f&#125;, validation loss: &#123;:.4f&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> accuracy<span class="token punctuation">,</span> validation_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> model_dir <span class="token operator">/</span> <span class="token string-interpolation"><span class="token string">f"model_</span><span class="token interpolation"><span class="token punctuation">&#123;</span>epoch<span class="token punctuation">&#125;</span></span><span class="token string">.pt"</span></span><span class="token punctuation">)</span>

    <span class="token comment"># 保存最好的模型</span>
    <span class="token keyword">if</span> accuracy <span class="token operator">></span> best_accuracy<span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> model_dir <span class="token operator">/</span> <span class="token string-interpolation"><span class="token string">f"model_best.pt"</span></span><span class="token punctuation">)</span>
        best_accuracy <span class="token operator">=</span> accuracy

<span class="token comment"># 加载最好的模型，然后进行测试集的预测</span>
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_dir <span class="token operator">/</span> <span class="token string-interpolation"><span class="token string">f"model_best.pt"</span></span><span class="token punctuation">)</span>
model <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

test_dataset <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span><span class="token string">'test'</span><span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span>

results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> inputs<span class="token punctuation">,</span> ids <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
    outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    outputs <span class="token operator">=</span> <span class="token punctuation">(</span>outputs <span class="token operator">>=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ids <span class="token operator">=</span> ids<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
    results <span class="token operator">=</span> results <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">,</span> result<span class="token punctuation">)</span> <span class="token keyword">for</span> result<span class="token punctuation">,</span> <span class="token builtin">id</span> <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> ids<span class="token punctuation">)</span><span class="token punctuation">]</span>

test_label <span class="token operator">=</span> <span class="token punctuation">[</span>pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> pair <span class="token keyword">in</span> results<span class="token punctuation">]</span>
test_data<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_label

test_data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">,</span><span class="token string">'label'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'result.csv'</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="api-py"><a href="#api-py" class="headerlink" title="api.py"></a>api.py</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> copy
<span class="token keyword">import</span> zhipuai
<span class="token keyword">import</span> time
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm

train <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'train.csv'</span><span class="token punctuation">)</span>
test <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'test.csv'</span><span class="token punctuation">)</span>

train<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> train<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
test<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> test<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

zhipuai<span class="token punctuation">.</span>api_key <span class="token operator">=</span> <span class="token string">"YOUR_API_KEY"</span>

n <span class="token operator">=</span> <span class="token number">5</span>
prompt_data <span class="token operator">=</span> train<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>n<span class="token operator">=</span>n<span class="token punctuation">)</span>
prompt_data <span class="token operator">=</span> prompt_data<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>prompt_data<span class="token punctuation">)</span>

tmp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>prompt_data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    item <span class="token operator">=</span> prompt_data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    instruction <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span>
        <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f"将给定的文本分成两类，并给出标签0或1，给定文本如下：</span><span class="token interpolation"><span class="token punctuation">&#123;</span>item<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span>
    <span class="token punctuation">&#125;</span>
    answer <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span>
        <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span>
    <span class="token punctuation">&#125;</span>
    tmp<span class="token punctuation">.</span>append<span class="token punctuation">(</span>instruction<span class="token punctuation">)</span>
    tmp<span class="token punctuation">.</span>append<span class="token punctuation">(</span>answer<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>tmp<span class="token punctuation">)</span>

test_item <span class="token operator">=</span> test<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>


<span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>test_item<span class="token punctuation">,</span> tmp<span class="token punctuation">)</span><span class="token punctuation">:</span>
    prompt <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>tmp<span class="token punctuation">)</span>
    test_instruction <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span>
        <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f"将给定的文本分成两类，并给出标签0或1，给定文本如下：</span><span class="token interpolation"><span class="token punctuation">&#123;</span>test_item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span>
    <span class="token punctuation">&#125;</span>
    prompt<span class="token punctuation">.</span>append<span class="token punctuation">(</span>test_instruction<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
    <span class="token comment"># response = zhipuai.model_api.invoke(</span>
    <span class="token comment">#     model="chatglm_pro",</span>
    <span class="token comment">#     prompt=prompt</span>
    <span class="token comment"># )</span>
    <span class="token comment"># print(response)</span>


predict<span class="token punctuation">(</span>test_item<span class="token operator">=</span>test_item<span class="token punctuation">,</span> tmp<span class="token operator">=</span>tmp<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="ernie-py"><a href="#ernie-py" class="headerlink" title="ernie.py"></a>ernie.py</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np <span class="token comment"># 数值计算</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token comment"># 数据分析</span>
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm <span class="token comment"># 进度条显示</span>
<span class="token keyword">import</span> paddle <span class="token comment"># PaddlePaddle 深度学习框架</span>
<span class="token keyword">from</span> paddlenlp<span class="token punctuation">.</span>transformers <span class="token keyword">import</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> AutoTokenizer <span class="token comment"># 飞桨自然语言处理工具包（模型、分词器）</span>
<span class="token keyword">from</span> paddle<span class="token punctuation">.</span>io <span class="token keyword">import</span> DataLoader <span class="token comment"># 数据加载器</span>
<span class="token keyword">from</span> paddlenlp<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> MapDataset <span class="token comment"># 数据集转换</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split <span class="token comment"># 训练集与验证集拆分</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt <span class="token comment"># 绘图</span>

data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"/home/aistudio/data/ChatGPT生成文本检测器公开数据-更新/train.csv"</span><span class="token punctuation">)</span> <span class="token comment"># 加载赛事提供的训练数据</span>
test_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"/home/aistudio/data/ChatGPT生成文本检测器公开数据-更新/test.csv"</span><span class="token punctuation">)</span> <span class="token comment"># 加载赛事所需提交的测试数据</span>
data<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>frac<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 随机查看 5 行训练数据中的内容</span>

<span class="token comment"># 载入模型与分词器</span>

<span class="token comment"># 使用 ernie-3.0-mini-zh 序列分类模型，并将分类类别数设置为 2</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"ernie-3.0-mini-zh"</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment"># 使用 ernie-3.0-mini-zh 分词器</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"ernie-3.0-mini-zh"</span><span class="token punctuation">)</span>

<span class="token comment"># 定义 AdamW 优化器，学习率为 0.000001</span>
optimizer <span class="token operator">=</span> paddle<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>AdamW<span class="token punctuation">(</span><span class="token number">1e-5</span><span class="token punctuation">,</span> parameters<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 定义损失函数为交叉熵函数，计算每个 mini batch 的均值</span>
loss_fn <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>loss<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'mean'</span><span class="token punctuation">)</span>

<span class="token comment"># 按照 10% 的比例划分训练集与验证集</span>
train_data<span class="token punctuation">,</span> valid_data <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>data<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>

<span class="token comment"># 下面就是一堆操作，把数据变成数据加载器可以识别的格式，自定义数据集类也是同样的效果</span>
train_dict <span class="token operator">=</span> train_data<span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span>orient<span class="token operator">=</span><span class="token string">'records'</span><span class="token punctuation">)</span>
valid_dict <span class="token operator">=</span> valid_data<span class="token punctuation">.</span>to_dict<span class="token punctuation">(</span>orient<span class="token operator">=</span><span class="token string">'records'</span><span class="token punctuation">)</span>
train_ds <span class="token operator">=</span> MapDataset<span class="token punctuation">(</span>train_dict<span class="token punctuation">)</span>
valid_ds <span class="token operator">=</span> MapDataset<span class="token punctuation">(</span>valid_dict<span class="token punctuation">)</span>

<span class="token comment"># 将整体数据拆分为 30 份，放入数据加载器，就是一次性会有 &lt;总样本数 / 30> 份数据同时并行计算，份数越多，并行越多，显存占用越大，需要根据需求来选择</span>
train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dict<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">60</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment"># 训练数据可以随机打乱，让模型更好地学习，减轻学习到无关特征的问题</span>
valid_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>valid_dict<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">60</span><span class="token punctuation">)</span> <span class="token comment"># 这里用的是 V100 32G，如果是显存更小的卡，需要调小一点，不然会炸显存</span>

epochs<span class="token operator">=</span><span class="token number">200</span>
best_accuracy<span class="token operator">=</span><span class="token number">0</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 训练 30 轮</span>
    <span class="token comment"># 训练过程</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 切换模型为训练模式</span>
    <span class="token keyword">for</span> batch_x <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 每次从数据加载器读入一批(batch)数据</span>
        X <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch_x<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">1015</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment"># 将数据转换为模块可处理的数据形式</span>
        input_ids <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"int32"</span><span class="token punctuation">)</span> <span class="token comment"># 将 input_ids 变为张量，方便并行计算</span>
        token_type_ids <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token string">'token_type_ids'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"int32"</span><span class="token punctuation">)</span> <span class="token comment"># 将 token_type_ids 变为张量</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> token_type_ids<span class="token punctuation">)</span> <span class="token comment"># 将数据读入模型，并得到计算后的结果</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>batch_x<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"int32"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 对比预测结果与真实结果，计算损失函数的值</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 反向传播，计算梯度</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 优化器根据梯度与学习率调整模型参数</span>
        optimizer<span class="token punctuation">.</span>clear_gradients<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 清空梯度，避免下次梯度计算时累加</span>

    <span class="token comment"># 验证过程</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 切换模型为验证模式</span>
    val_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment"># 验证集数据的损失函数合集</span>
    <span class="token keyword">with</span> paddle<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 在模型验证时，只做前向计算，因此不需要保存梯度信息</span>
        <span class="token keyword">for</span> batch_x <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>valid_loader<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 下面的操作与训练过程相同</span>
            X <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch_x<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">1015</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            input_ids <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"int32"</span><span class="token punctuation">)</span>
            token_type_ids <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token string">'token_type_ids'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"int32"</span><span class="token punctuation">)</span>
            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> token_type_ids<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>batch_x<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"int32"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            val_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 将计算出的损失函数值存入合集</span>
            
    <span class="token comment"># 打印本轮训练的验证集损失函数值，与预测正确率</span>
    accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> batch_x<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch &#123;0&#125;, Val loss &#123;1:3f&#125;, Val Accuracy &#123;2:3f&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
    epoch<span class="token punctuation">,</span>
    np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>val_loss<span class="token punctuation">)</span><span class="token punctuation">,</span> 
    <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> batch_x<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> accuracy<span class="token operator">></span>best_accuracy<span class="token punctuation">:</span>
        paddle<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">"/home/aistudio/work/model_best.pdparams"</span><span class="token punctuation">)</span>
        paddle<span class="token punctuation">.</span>save<span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"/home/aistudio/work/optimizer_best.pdopt"</span><span class="token punctuation">)</span>
        best_accuracy<span class="token operator">=</span>accuracy

paddle<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">"/home/aistudio/work/model.pdparams"</span><span class="token punctuation">)</span>
paddle<span class="token punctuation">.</span>save<span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"/home/aistudio/work/optimizer.pdopt"</span><span class="token punctuation">)</span>

<span class="token comment"># 如果你拿到了模型参数（在 AIStudio 中提供），你可以运行这行代码，如果直接运行模型，则没有必要运行</span>

<span class="token comment"># 载入模型参数、优化器参数的最后一个epoch保存的检查点</span>
layer_state_dict <span class="token operator">=</span> paddle<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"/home/aistudio/work/model_best.pdparams"</span><span class="token punctuation">)</span>
opt_state_dict <span class="token operator">=</span> paddle<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"/home/aistudio/work/optimizer_best.pdopt"</span><span class="token punctuation">)</span>

<span class="token comment"># 将加载后的参数与模型关联起来</span>
model<span class="token punctuation">.</span>set_state_dict<span class="token punctuation">(</span>layer_state_dict<span class="token punctuation">)</span>
optimizer<span class="token punctuation">.</span>set_state_dict<span class="token punctuation">(</span>opt_state_dict<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">infer</span><span class="token punctuation">(</span>string<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> <span class="token builtin">int</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""将文本传入模型并返回预测结果
    
    输入：
        - string: str
            待预测的文本内容
    
    输出:
        - result: int
            模型的预测结果
    """</span>
    X <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token punctuation">[</span>string<span class="token punctuation">]</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">1015</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    input_ids <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"int32"</span><span class="token punctuation">)</span>
    token_type_ids <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token string">'token_type_ids'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"int32"</span><span class="token punctuation">)</span>
    pred <span class="token operator">=</span> model<span class="token punctuation">(</span>input_ids<span class="token punctuation">,</span> token_type_ids<span class="token punctuation">)</span>
    result <span class="token operator">=</span> pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 获取预测概率最大的那个类别</span>
    <span class="token keyword">return</span> result

test_data<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_data<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>infer<span class="token punctuation">)</span> <span class="token comment"># 将测试集的每个文本送入模型返回结果</span>
submit <span class="token operator">=</span> test_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 生成提交数据（就是把带结果的测试集丢掉内容，复制一份）</span>
submit<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"submit3.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token comment"># 保存 CSV 文件</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h2 id="更新日志"><a href="#更新日志" class="headerlink" title="更新日志"></a>更新日志</h2><p>2023年8月4日：跑通baseline并进行微调，收效甚微甚至不如baseline，仅提交了baseline，获得分数0.85+</p>
<p>2023年8月5日：跑通upper，获得分数0.91+</p>
<p>2023年8月6日：尝试使用BERT模型进行鉴别，效果比较好，获得分数0.93+</p>
<p>2023年8月7日：尝试使用大模型API进行分类，效果相当不理想；尝试使用ernie模型进行分类，分类效果随着训练轮数的增加而有一定程度的提升，得到0.98+、0.99+分数</p>
<blockquote>
<p>To Be Continued</p>
</blockquote>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">J&Ocean</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://jiang-wu-19.github.io/2023/08/06/ChatGPT%E7%94%9F%E6%88%90%E5%86%85%E5%AE%B9%E9%89%B4%E5%88%AB%E7%9A%84%E5%AE%9E%E7%8E%B0/">https://jiang-wu-19.github.io/2023/08/06/ChatGPT%E7%94%9F%E6%88%90%E5%86%85%E5%AE%B9%E9%89%B4%E5%88%AB%E7%9A%84%E5%AE%9E%E7%8E%B0/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">J&Ocean</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/NLP/">
                                    <span class="chip bg-color">NLP</span>
                                </a>
                            
                                <a href="/tags/Python/">
                                    <span class="chip bg-color">Python</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">请我喝杯奶茶吧~</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    
        <style>
    .valine-card {
        margin: 1.5rem auto;
    }

    .valine-card .card-content {
        padding: 20px 20px 5px 20px;
    }

    #vcomments textarea {
        box-sizing: border-box;
        background: url("/medias/comment_bg.png") 100% 100% no-repeat;
    }

    #vcomments p {
        margin: 2px 2px 10px;
        font-size: 1.05rem;
        line-height: 1.78rem;
    }

    #vcomments blockquote p {
        text-indent: 0.2rem;
    }

    #vcomments a {
        padding: 0 2px;
        color: #4cbf30;
        font-weight: 500;
        text-decoration: none;
    }

    #vcomments img {
        max-width: 100%;
        height: auto;
        cursor: pointer;
    }

    #vcomments ol li {
        list-style-type: decimal;
    }

    #vcomments ol,
    ul {
        display: block;
        padding-left: 2em;
        word-spacing: 0.05rem;
    }

    #vcomments ul li,
    ol li {
        display: list-item;
        line-height: 1.8rem;
        font-size: 1rem;
    }

    #vcomments ul li {
        list-style-type: disc;
    }

    #vcomments ul ul li {
        list-style-type: circle;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    #vcomments table, th, td {
        border: 0;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments h1 {
        font-size: 1.85rem;
        font-weight: bold;
        line-height: 2.2rem;
    }

    #vcomments h2 {
        font-size: 1.65rem;
        font-weight: bold;
        line-height: 1.9rem;
    }

    #vcomments h3 {
        font-size: 1.45rem;
        font-weight: bold;
        line-height: 1.7rem;
    }

    #vcomments h4 {
        font-size: 1.25rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    #vcomments h5 {
        font-size: 1.1rem;
        font-weight: bold;
        line-height: 1.4rem;
    }

    #vcomments h6 {
        font-size: 1rem;
        line-height: 1.3rem;
    }

    #vcomments p {
        font-size: 1rem;
        line-height: 1.5rem;
    }

    #vcomments hr {
        margin: 12px 0;
        border: 0;
        border-top: 1px solid #ccc;
    }

    #vcomments blockquote {
        margin: 15px 0;
        border-left: 5px solid #42b983;
        padding: 1rem 0.8rem 0.3rem 0.8rem;
        color: #666;
        background-color: rgba(66, 185, 131, .1);
    }

    #vcomments pre {
        font-family: monospace, monospace;
        padding: 1.2em;
        margin: .5em 0;
        background: #272822;
        overflow: auto;
        border-radius: 0.3em;
        tab-size: 4;
    }

    #vcomments code {
        font-family: monospace, monospace;
        padding: 1px 3px;
        font-size: 0.92rem;
        color: #e96900;
        background-color: #f8f8f8;
        border-radius: 2px;
    }

    #vcomments pre code {
        font-family: monospace, monospace;
        padding: 0;
        color: #e8eaf6;
        background-color: #272822;
    }

    #vcomments pre[class*="language-"] {
        padding: 1.2em;
        margin: .5em 0;
    }

    #vcomments code[class*="language-"],
    pre[class*="language-"] {
        color: #e8eaf6;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }

    #vcomments b,
    strong {
        font-weight: bold;
    }

    #vcomments dfn {
        font-style: italic;
    }

    #vcomments small {
        font-size: 85%;
    }

    #vcomments cite {
        font-style: normal;
    }

    #vcomments mark {
        background-color: #fcf8e3;
        padding: .2em;
    }

    #vcomments table, th, td {
        padding: 12px 13px;
        border: 1px solid #dfe2e5;
    }

    table tr:nth-child(2n), thead {
        background-color: #fafafa;
    }

    #vcomments table th {
        background-color: #f2f2f2;
        min-width: 80px;
    }

    #vcomments table td {
        min-width: 80px;
    }

    #vcomments [type="checkbox"]:not(:checked), [type="checkbox"]:checked {
        position: inherit;
        margin-left: -1.3rem;
        margin-right: 0.4rem;
        margin-top: -1px;
        vertical-align: middle;
        left: unset;
        visibility: visible;
    }
</style>

<div class="card valine-card" data-aos="fade-up">
    <div class="comment_headling" style="font-size: 20px; font-weight: 700; position: relative; padding-left: 20px; top: 15px; padding-bottom: 5px;">
        <i class="fas fa-comments fa-fw" aria-hidden="true"></i>
        <span>评论</span>
    </div>
    <div id="vcomments" class="card-content" style="display: grid">
    </div>
</div>

<script src="/libs/valine/av-min.js"></script>
<script src="/libs/valine/Valine.min.js"></script>
<script>
    new Valine({
        el: '#vcomments',
        appId: 'Nv6Wx6PAYH30bfcx7u0eDWHy-gzGzoHsz',
        appKey: 'IhPcpC3fDP8Ro7eaPakG2vSt',
        notify: 'false' === 'true',
        verify: 'false' === 'true',
        visitor: 'true' === 'true',
        avatar: 'mm',
        pageSize: '10',
        lang: 'zh-cn',
        placeholder: 'just go go'
    });
</script>

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/2023/08/06/ChatGPT%E7%94%9F%E6%88%90%E5%86%85%E5%AE%B9%E9%89%B4%E5%88%AB%E7%9A%84%E5%AE%9E%E7%8E%B0/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/23.jpg" class="responsive-img" alt="ChatGPT生成内容鉴别的实现">
                        
                        <span class="card-title">ChatGPT生成内容鉴别的实现</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NLP实践之GPT生成内容鉴别
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-08-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9A%91%E6%9C%9F%E5%AE%9E%E4%B9%A0/" class="post-category">
                                    暑期实习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/NLP/">
                        <span class="chip bg-color">NLP</span>
                    </a>
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2023/07/30/upper%E7%9A%84%E5%AE%9E%E7%8E%B0/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/12.jpg" class="responsive-img" alt="upper的实现">
                        
                        <span class="card-title">upper的实现</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            使用BERT模型提高准确率
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-07-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9A%91%E6%9C%9F%E5%AE%9E%E4%B9%A0/" class="post-category">
                                    暑期实习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/NLP/">
                        <span class="chip bg-color">NLP</span>
                    </a>
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: J&amp;Ocean BLOG<br />'
            + '文章作者: J&amp;Ocean<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023</span>
            
            <span id="year">2023</span>
            <a href="/about" target="_blank">J&Ocean</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">102.3k</span>&nbsp;字
            
            
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2023";
                    var startMonth = "7";
                    var startDate = "2";
                    var startHour = "12";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/JIANG-Wu-19" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:wujiang0319@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=870027163" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 870027163" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/bei-wei-xiao-wu-32" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/bei-wei-xiao-wu-32" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
